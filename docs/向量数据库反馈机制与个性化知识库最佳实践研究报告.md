# å‘é‡æ•°æ®åº“åé¦ˆæœºåˆ¶ä¸ä¸ªæ€§åŒ–çŸ¥è¯†åº“æœ€ä½³å®è·µç ”ç©¶æŠ¥å‘Š

> **é¡¹ç›®**: Voice Notification Project - æ™ºèƒ½è¯­éŸ³æ€»ç»“å›å¤
> **ä½œè€…**: å£®çˆ¸
> **æ—¥æœŸ**: 2025-01-14
> **ç‰ˆæœ¬**: 1.0

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šæ·±å…¥ç ”ç©¶äº†ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1. **å‘é‡æ•°æ®åº“çš„ç”¨æˆ·åé¦ˆæœºåˆ¶æœ€ä½³å®è·µ** - å¦‚ä½•é€šè¿‡ RLHF å’Œè´¨é‡æ§åˆ¶é˜²æ­¢ä½è´¨é‡å†…å®¹æ±¡æŸ“æ•°æ®åº“
2. **ä¸ªæ€§åŒ–çŸ¥è¯†åº“æ„å»ºæ–¹æ³•** - å¦‚ä½•æ•´åˆå¤šæºæ•°æ®æ„å»ºä¸ªæ€§åŒ– RAG ç³»ç»Ÿ

ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæœ€ä½³å®è·µæ˜¯é‡‡ç”¨**æ··åˆåé¦ˆæœºåˆ¶**ï¼ˆæ˜¾å¼+éšå¼ï¼‰+ **åŒå±‚è´¨é‡æ§åˆ¶**ï¼ˆè‡ªåŠ¨è¯„åˆ†+äººå·¥å®¡æ ¸ï¼‰+ **HybridRAGæ¶æ„**ï¼ˆå‘é‡æ£€ç´¢+çŸ¥è¯†å›¾è°±ï¼‰çš„ç»„åˆæ–¹æ¡ˆã€‚

---

## ç›®å½•

- [ä¸€ã€å‘é‡æ•°æ®åº“ç”¨æˆ·åé¦ˆæœºåˆ¶æœ€ä½³å®è·µ](#ä¸€å‘é‡æ•°æ®åº“ç”¨æˆ·åé¦ˆæœºåˆ¶æœ€ä½³å®è·µ)
  - [1.1 RLHF åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨](#11-rlhf-åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨)
  - [1.2 åé¦ˆæ”¶é›†æœºåˆ¶è®¾è®¡](#12-åé¦ˆæ”¶é›†æœºåˆ¶è®¾è®¡)
  - [1.3 è´¨é‡æ§åˆ¶ä¸æ±¡æŸ“é˜²æŠ¤](#13-è´¨é‡æ§åˆ¶ä¸æ±¡æŸ“é˜²æŠ¤)
  - [1.4 åé¦ˆæƒé‡è°ƒæ•´ç­–ç•¥](#14-åé¦ˆæƒé‡è°ƒæ•´ç­–ç•¥)
- [äºŒã€ä¸ªæ€§åŒ–çŸ¥è¯†åº“æ„å»ºæ–¹æ³•](#äºŒä¸ªæ€§åŒ–çŸ¥è¯†åº“æ„å»ºæ–¹æ³•)
  - [2.1 å¤šæºæ•°æ®æ•´åˆç­–ç•¥](#21-å¤šæºæ•°æ®æ•´åˆç­–ç•¥)
  - [2.2 HybridRAG æ¶æ„è®¾è®¡](#22-hybridrag-æ¶æ„è®¾è®¡)
  - [2.3 ä¸ªäººåå¥½æ¨¡å‹æ„å»º](#23-ä¸ªäººåå¥½æ¨¡å‹æ„å»º)
  - [2.4 å¯¹è¯è®°å¿†ç®¡ç†](#24-å¯¹è¯è®°å¿†ç®¡ç†)
- [ä¸‰ã€æŠ€æœ¯æ–¹æ¡ˆä¸å®ç°å»ºè®®](#ä¸‰æŠ€æœ¯æ–¹æ¡ˆä¸å®ç°å»ºè®®)
  - [3.1 æ¨èæŠ€æœ¯æ ˆ](#31-æ¨èæŠ€æœ¯æ ˆ)
  - [3.2 å®ç°è·¯çº¿å›¾](#32-å®ç°è·¯çº¿å›¾)
  - [3.3 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#33-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
- [å››ã€å‚è€ƒèµ„æºä¸å¼€æºé¡¹ç›®](#å››å‚è€ƒèµ„æºä¸å¼€æºé¡¹ç›®)

---

## ä¸€ã€å‘é‡æ•°æ®åº“ç”¨æˆ·åé¦ˆæœºåˆ¶æœ€ä½³å®è·µ

### 1.1 RLHF åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨

#### æ ¸å¿ƒæ¦‚å¿µ

**RLHF (Reinforcement Learning from Human Feedback)** æ˜¯é€šè¿‡äººç±»åé¦ˆè®­ç»ƒ"å¥–åŠ±æ¨¡å‹"ï¼Œç„¶åä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ– AI æ€§èƒ½çš„æœºå™¨å­¦ä¹ æŠ€æœ¯ã€‚

#### åœ¨å‘é‡æ•°æ®åº“ä¸­çš„ä¸‰å¤§åº”ç”¨åœºæ™¯

1. **æ£€ç´¢è´¨é‡ä¼˜åŒ–**
   - ä½¿ç”¨äººç±»åé¦ˆè°ƒæ•´æ£€ç´¢æ’åºæƒé‡
   - æ ¹æ®ç”¨æˆ·æ»¡æ„åº¦é‡æ–°æ’åºæœç´¢ç»“æœ
   - é€šè¿‡ A/B æµ‹è¯•éªŒè¯æ”¹è¿›æ•ˆæœ

2. **å†…å®¹ç”Ÿæˆè´¨é‡æ§åˆ¶**
   - åœ¨ç”Ÿæˆå†…å®¹å…¥åº“å‰æ”¶é›†è´¨é‡è¯„åˆ†
   - ä½¿ç”¨å¥–åŠ±æ¨¡å‹é¢„æµ‹å†…å®¹è´¨é‡
   - è‡ªåŠ¨è¿‡æ»¤ä½è´¨é‡å†…å®¹

3. **ä¸ªæ€§åŒ–åå¥½å­¦ä¹ **
   - å°†ç”¨æˆ·åé¦ˆä½œä¸ºä¸ªæ€§åŒ–ä¿¡å·
   - æ„å»ºç”¨æˆ·ç‰¹å®šçš„å¥–åŠ±æ¨¡å‹
   - åŠ¨æ€è°ƒæ•´æ£€ç´¢å’Œç”Ÿæˆç­–ç•¥

#### RLHF å®ç°æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. åˆå§‹æ¨¡å‹    â”‚  ä½¿ç”¨åŸºç¡€ LLM + å‘é‡æ£€ç´¢
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. æ”¶é›†åé¦ˆ    â”‚  ç”¨æˆ·å¯¹ç”Ÿæˆå†…å®¹è¯„åˆ†/æ¯”è¾ƒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. è®­ç»ƒå¥–åŠ±æ¨¡å‹ â”‚  ä½¿ç”¨äººç±»åå¥½æ•°æ®è®­ç»ƒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. RL ä¼˜åŒ–     â”‚  ä½¿ç”¨ PPO ç­‰ç®—æ³•ä¼˜åŒ–ç­–ç•¥
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. è¿­ä»£æ”¹è¿›    â”‚  æŒç»­æ”¶é›†åé¦ˆï¼Œé‡å¤æµç¨‹
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å…³é”®æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

| æŒ‘æˆ˜ | è§£å†³æ–¹æ¡ˆ |
|------|---------|
| **äººç±»åé¦ˆè´¨é‡ä¸ä¸€è‡´** | ä½¿ç”¨å¤šä¸ªæ ‡æ³¨å‘˜+å…±è¯†æœºåˆ¶ï¼›æ£€æµ‹å’Œè¿‡æ»¤å¼‚å¸¸åé¦ˆ |
| **æ•°æ®åå·®å’Œè¿‡æ‹Ÿåˆ** | ç¡®ä¿æ ‡æ³¨å‘˜å¤šæ ·æ€§ï¼›ä½¿ç”¨æ­£åˆ™åŒ–æŠ€æœ¯ |
| **æ¶æ„/å¯¹æŠ—æ€§åé¦ˆ** | å®æ–½ä¿¡èª‰è¯„åˆ†ç³»ç»Ÿï¼›å¼‚å¸¸æ£€æµ‹ç®—æ³• |
| **æˆæœ¬é«˜æ˜‚** | æ··åˆä½¿ç”¨æ˜¾å¼å’Œéšå¼åé¦ˆï¼›ä¸»åŠ¨å­¦ä¹ é€‰æ‹©å…³é”®æ ·æœ¬ |

### 1.2 åé¦ˆæ”¶é›†æœºåˆ¶è®¾è®¡

#### æ˜¾å¼åé¦ˆ vs éšå¼åé¦ˆ

**æ˜¾å¼åé¦ˆ**ï¼ˆExplicit Feedbackï¼‰
- **å®šä¹‰**: ç”¨æˆ·ä¸»åŠ¨æä¾›çš„ç›´æ¥æ„å›¾è¡¨è¾¾
- **å½¢å¼**:
  - è¯„åˆ†ï¼ˆ1-5æ˜Ÿï¼‰
  - ç‚¹èµ/ç‚¹è¸©ï¼ˆğŸ‘/ğŸ‘ï¼‰
  - æ–‡æœ¬è¯„è®ºå’Œç†ç”±
  - æˆå¯¹æ¯”è¾ƒï¼ˆA vs B å“ªä¸ªæ›´å¥½ï¼‰
- **ä¼˜ç‚¹**:
  - æ¸…æ™°æ˜ç¡®ï¼Œæ˜“äºç†è§£
  - æä¾›ç”¨æˆ·é€æ˜åº¦å’Œæ§åˆ¶æ„Ÿ
  - é€‚åˆè®­ç»ƒç²¾ç¡®çš„å¥–åŠ±æ¨¡å‹
- **ç¼ºç‚¹**:
  - ç”¨æˆ·å‚ä¸æˆæœ¬é«˜ï¼Œæ•°æ®ç¨€ç–
  - å¯èƒ½äº§ç”Ÿ"è°ƒæŸ¥ç–²åŠ³"
  - æç«¯è¯„åˆ†åå·®ï¼ˆåªæœ‰éå¸¸å¥½/å·®æ‰è¯„åˆ†ï¼‰

**éšå¼åé¦ˆ**ï¼ˆImplicit Feedbackï¼‰
- **å®šä¹‰**: ä»ç”¨æˆ·è¡Œä¸ºä¸­æ¨æ–­çš„åå¥½ä¿¡å·
- **å½¢å¼**:
  - ç‚¹å‡»ç‡ï¼ˆCTRï¼‰
  - åœç•™æ—¶é—´/é˜…è¯»æ·±åº¦
  - å¤åˆ¶å†…å®¹è¡Œä¸º
  - åç»­ç›¸å…³æŸ¥è¯¢
  - æ˜¯å¦ä¿®æ”¹/åˆ é™¤ç”Ÿæˆå†…å®¹
- **ä¼˜ç‚¹**:
  - è‡ªåŠ¨æ”¶é›†ï¼Œæ•°æ®ä¸°å¯Œ
  - ç”¨æˆ·æ— æ„ŸçŸ¥ï¼Œæ— å¿ƒç†è´Ÿæ‹…
  - åæ˜ çœŸå®è¡Œä¸ºè€Œéå£°æ˜åå¥½
- **ç¼ºç‚¹**:
  - ä¿¡å·æ¨¡ç³Šï¼ˆç‚¹å‡»â‰ æ»¡æ„ï¼‰
  - éœ€è¦é¢å¤–å¤„ç†æ¨æ–­åå¥½
  - å¯èƒ½å—å¤–éƒ¨å› ç´ å¹²æ‰°

#### æ¨èçš„æ··åˆåé¦ˆç­–ç•¥

```powershell
# åé¦ˆæ”¶é›†ä¼˜å…ˆçº§
[PSCustomObject]@{
    åœºæ™¯ = "AIç”Ÿæˆè¯­éŸ³é€šçŸ¥å"
    æ˜¾å¼åé¦ˆ = @(
        "è½»é‡çº§å¿«é€Ÿè¯„åˆ†ï¼ˆğŸ‘/ğŸ‘ï¼‰",
        "å¯é€‰çš„æ”¹è¿›å»ºè®®æ–‡æœ¬æ¡†"
    )
    éšå¼åé¦ˆ = @(
        "æ˜¯å¦æ’­æ”¾å®Œæ•´éŸ³é¢‘",
        "æ˜¯å¦é‡å¤æ’­æ”¾",
        "æ˜¯å¦æ‰‹åŠ¨ä¿®æ”¹æ–‡æœ¬",
        "åç»­ç±»ä¼¼é€šçŸ¥çš„äº¤äº’æ¨¡å¼"
    )
    è§¦å‘æ—¶æœº = "æ¯æ¬¡ç”Ÿæˆåæ˜¾ç¤ºè¯„åˆ†æŒ‰é’®ï¼Œä½†ä¸å¼ºåˆ¶"
    æ•°æ®æƒé‡ = "æ˜¾å¼åé¦ˆæƒé‡ x3ï¼Œéšå¼åé¦ˆä½œä¸ºè¾…åŠ©"
}
```

#### åé¦ˆæ”¶é›†æœ€ä½³å®è·µ

1. **æœ€å°åŒ–ç”¨æˆ·æ‘©æ“¦**
   - ä½¿ç”¨ä¸€é”®è¯„åˆ†ï¼ˆğŸ‘/ğŸ‘ï¼‰ï¼Œé¿å…å¤æ‚è¡¨å•
   - å¯é€‰çš„è¯¦ç»†åé¦ˆï¼Œä¸å¼ºåˆ¶
   - åœ¨è‡ªç„¶äº¤äº’æµç¨‹ä¸­åµŒå…¥åé¦ˆç‚¹

2. **å¤šç»´åº¦è¯„åˆ†**
   ```json
   {
     "overall_quality": 4,
     "accuracy": 5,
     "tone_appropriateness": 3,
     "length": 4,
     "actionability": 5,
     "timestamp": "2025-01-14T10:30:00Z",
     "feedback_type": "explicit"
   }
   ```

3. **æˆå¯¹æ¯”è¾ƒ**ï¼ˆç”¨äºæ¨¡ç³Šåœºæ™¯ï¼‰
   - å±•ç¤ºä¸¤ä¸ªä¸åŒç”Ÿæˆç»“æœï¼šA vs B
   - ç”¨æˆ·é€‰æ‹©æ›´å¥½çš„ç‰ˆæœ¬
   - ä½¿ç”¨ Elo è¯„åˆ†ç³»ç»Ÿèšåˆæ’å

4. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥åé¦ˆ**
   - è®°å½•åé¦ˆæ—¶çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆæŸ¥è¯¢ã€æ£€ç´¢ç»“æœã€ç”Ÿæˆå‚æ•°ï¼‰
   - ç”¨äºåç»­åˆ†æå’Œæ¨¡å‹æ”¹è¿›

### 1.3 è´¨é‡æ§åˆ¶ä¸æ±¡æŸ“é˜²æŠ¤

#### ä¸‰å±‚è´¨é‡æ§åˆ¶æœºåˆ¶

**ç¬¬ä¸€å±‚ï¼šç”Ÿæˆå‰è¿‡æ»¤ï¼ˆPre-generation Filterï¼‰**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥æŸ¥è¯¢è´¨é‡æ£€æŸ¥                    â”‚
â”‚  - æ£€æµ‹æ¶æ„æ³¨å…¥                     â”‚
â”‚  - éªŒè¯æŸ¥è¯¢åˆç†æ€§                   â”‚
â”‚  - æ£€æŸ¥éšç§æ•æ„Ÿä¿¡æ¯                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
         [åˆæ ¼] / [æ‹’ç»]
```

**ç¬¬äºŒå±‚ï¼šç”Ÿæˆåè¯„åˆ†ï¼ˆPost-generation Scoringï¼‰**
```powershell
# è‡ªåŠ¨è´¨é‡è¯„åˆ†æ¨¡å‹
function Get-ContentQualityScore {
    param($GeneratedContent, $SourceContext)

    $Scores = @{
        # äº‹å®ä¸€è‡´æ€§ï¼ˆä¸æ£€ç´¢å†…å®¹å¯¹æ¯”ï¼‰
        Faithfulness = Get-FactualConsistency -Content $GeneratedContent -Source $SourceContext

        # ç­”æ¡ˆç›¸å…³æ€§ï¼ˆä¸æŸ¥è¯¢çš„åŒ¹é…åº¦ï¼‰
        AnswerRelevance = Get-QueryRelevance -Content $GeneratedContent -Query $Query

        # ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼ˆæ£€ç´¢å†…å®¹è´¨é‡ï¼‰
        ContextRelevance = Get-ContextQuality -Context $SourceContext

        # è¯­è¨€è´¨é‡ï¼ˆè¯­æ³•ã€æµç•…åº¦ï¼‰
        LanguageQuality = Get-LanguageQuality -Content $GeneratedContent

        # å®‰å…¨æ€§ï¼ˆæœ‰å®³å†…å®¹æ£€æµ‹ï¼‰
        SafetyScore = Get-SafetyScore -Content $GeneratedContent
    }

    # åŠ æƒæ€»åˆ†
    $TotalScore = (
        $Scores.Faithfulness * 0.3 +
        $Scores.AnswerRelevance * 0.25 +
        $Scores.ContextRelevance * 0.2 +
        $Scores.LanguageQuality * 0.15 +
        $Scores.SafetyScore * 0.1
    )

    return @{
        TotalScore = $TotalScore
        DetailedScores = $Scores
        ShouldStoreInDB = ($TotalScore -ge 0.7)  # é˜ˆå€¼æ§åˆ¶
    }
}
```

**ç¬¬ä¸‰å±‚ï¼šå…¥åº“å‰å®¡æ ¸ï¼ˆPre-storage Reviewï¼‰**

| å®¡æ ¸ç±»å‹ | è§¦å‘æ¡ä»¶ | å¤„ç†æ–¹å¼ |
|---------|---------|---------|
| **è‡ªåŠ¨å…¥åº“** | è´¨é‡åˆ† â‰¥ 0.85 ä¸”æ— å®‰å…¨é£é™© | ç›´æ¥å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ |
| **å»¶è¿Ÿå…¥åº“** | 0.7 â‰¤ è´¨é‡åˆ† < 0.85 | æ ‡è®°ä¸º"å¾…éªŒè¯"ï¼Œæ”¶é›†æ›´å¤šåé¦ˆåå†³å®š |
| **äººå·¥å®¡æ ¸** | è´¨é‡åˆ† < 0.7 æˆ–å®‰å…¨è­¦å‘Š | è¿›å…¥å®¡æ ¸é˜Ÿåˆ—ï¼Œäººå·¥åˆ¤æ–­ |
| **æ‹’ç»å…¥åº“** | è´¨é‡åˆ† < 0.5 æˆ–ä¸¥é‡è¿è§„ | ä¸¢å¼ƒï¼Œè®°å½•æ—¥å¿—ç”¨äºæ¨¡å‹æ”¹è¿› |

#### æ±¡æŸ“é˜²æŠ¤ç­–ç•¥

1. **æ•°æ®éš”ç¦»ï¼ˆData Isolationï¼‰**
   ```
   å‘é‡æ•°æ®åº“åˆ†å±‚ï¼š
   â”œâ”€â”€ Tier 1: é«˜è´¨é‡äººå·¥éªŒè¯æ•°æ®ï¼ˆæƒé‡ 1.0ï¼‰
   â”œâ”€â”€ Tier 2: è‡ªåŠ¨è¯„åˆ† > 0.85 æ•°æ®ï¼ˆæƒé‡ 0.8ï¼‰
   â”œâ”€â”€ Tier 3: ç”¨æˆ·åé¦ˆæ­£é¢æ•°æ®ï¼ˆæƒé‡ 0.6ï¼‰
   â””â”€â”€ Tier 4: å®éªŒ/æµ‹è¯•æ•°æ®ï¼ˆæƒé‡ 0.3ï¼Œä»…ç”¨äº A/B æµ‹è¯•ï¼‰
   ```

2. **ç‰ˆæœ¬æ§åˆ¶ä¸å›æ»š**
   - ä¸ºå‘é‡æ•°æ®åº“å¯ç”¨å¿«ç…§åŠŸèƒ½
   - å®šæœŸå¤‡ä»½é«˜è´¨é‡æ•°æ®é›†
   - æ£€æµ‹åˆ°è´¨é‡ä¸‹é™æ—¶å¿«é€Ÿå›æ»š

3. **å¼‚å¸¸æ£€æµ‹**
   ```python
   # ç›‘æ§å…¥åº“æ•°æ®çš„åˆ†å¸ƒå˜åŒ–
   def detect_data_drift(new_embeddings, baseline_embeddings):
       # ä½¿ç”¨ç»Ÿè®¡è·ç¦»æ£€æµ‹åˆ†å¸ƒåç§»
       kl_divergence = calculate_kl_divergence(new_embeddings, baseline_embeddings)

       if kl_divergence > threshold:
           alert("æ•°æ®åˆ†å¸ƒå¼‚å¸¸ï¼å¯èƒ½å­˜åœ¨è´¨é‡é—®é¢˜")
           trigger_manual_review()
   ```

4. **ç”¨æˆ·ä¿¡èª‰ç³»ç»Ÿ**
   - è·Ÿè¸ªæ¯ä¸ªç”¨æˆ·/ä¼šè¯çš„åé¦ˆè´¨é‡
   - å¯¹ä¸€è‡´æ€§ä½æˆ–æ¶æ„åé¦ˆé™æƒ
   - ä¼˜å…ˆä¿¡ä»»é«˜ä¿¡èª‰ç”¨æˆ·çš„æ ‡æ³¨

### 1.4 åé¦ˆæƒé‡è°ƒæ•´ç­–ç•¥

#### æ—¶é—´è¡°å‡æ¨¡å‹

æ—§åé¦ˆçš„æƒé‡åº”éšæ—¶é—´é™ä½ï¼Œå› ä¸ºç”¨æˆ·åå¥½å’Œå†…å®¹è´¨é‡æ ‡å‡†ä¼šæ¼”å˜ã€‚

```python
import numpy as np
from datetime import datetime, timedelta

def calculate_temporal_weight(feedback_timestamp, decay_rate=0.1):
    """
    æ—¶é—´è¡°å‡æƒé‡è®¡ç®—

    å‚æ•°:
        feedback_timestamp: åé¦ˆæ—¶é—´æˆ³
        decay_rate: è¡°å‡ç‡ï¼ˆæ¯30å¤©ï¼‰

    è¿”å›:
        æ—¶é—´æƒé‡ (0-1)
    """
    days_old = (datetime.now() - feedback_timestamp).days
    weight = np.exp(-decay_rate * (days_old / 30))
    return max(weight, 0.1)  # æœ€ä½ä¿ç•™ 10% æƒé‡
```

#### ç»¼åˆæƒé‡å…¬å¼

```python
def calculate_final_weight(feedback):
    """
    ç»¼åˆæƒé‡ = åŸºç¡€æƒé‡ Ã— æ—¶é—´æƒé‡ Ã— ç”¨æˆ·ä¿¡èª‰ Ã— åé¦ˆç±»å‹æƒé‡
    """
    base_weights = {
        'explicit_rating': 1.0,      # æ˜¾å¼è¯„åˆ†
        'implicit_click': 0.3,       # ç‚¹å‡»è¡Œä¸º
        'implicit_duration': 0.4,    # åœç•™æ—¶é—´
        'comparison': 1.2,           # æˆå¯¹æ¯”è¾ƒï¼ˆæœ€å¯é ï¼‰
        'text_feedback': 0.8         # æ–‡æœ¬è¯„è®º
    }

    feedback_weight = (
        base_weights.get(feedback.type, 0.5) *
        calculate_temporal_weight(feedback.timestamp) *
        feedback.user_reputation *
        feedback.confidence_score  # æ¨¡å‹å¯¹åé¦ˆçš„ç½®ä¿¡åº¦
    )

    return feedback_weight
```

#### åŠ¨æ€æƒé‡è°ƒæ•´ï¼ˆActive Learningï¼‰

**ä¸»åŠ¨å­¦ä¹ ç­–ç•¥**: ä¼˜å…ˆæ”¶é›†å¯¹æ¨¡å‹æ”¹è¿›æœ€æœ‰ä»·å€¼çš„åé¦ˆ

```python
def select_samples_for_feedback(candidate_items, model, budget=10):
    """
    ä½¿ç”¨ä¸ç¡®å®šæ€§é‡‡æ ·é€‰æ‹©æœ€éœ€è¦äººç±»åé¦ˆçš„æ ·æœ¬

    ç­–ç•¥:
    1. æ¨¡å‹é¢„æµ‹åˆ†æ•°æ¥è¿‘å†³ç­–è¾¹ç•Œï¼ˆ0.5é™„è¿‘ï¼‰çš„é¡¹ç›®
    2. é«˜æ–¹å·®é¢„æµ‹ï¼ˆæ¨¡å‹ä¸ç¡®å®šï¼‰
    3. ä»£è¡¨æ€§æ ·æœ¬ï¼ˆè¦†ç›–ä¸åŒæ•°æ®ç°‡ï¼‰
    """
    uncertainty_scores = []

    for item in candidate_items:
        pred_score = model.predict_quality(item)
        # è®¡ç®—ä¸ç¡®å®šæ€§ï¼šè·ç¦» 0.5 è¶Šè¿‘è¶Šä¸ç¡®å®š
        uncertainty = 1 - abs(pred_score - 0.5) * 2
        uncertainty_scores.append(uncertainty)

    # é€‰æ‹©ä¸ç¡®å®šæ€§æœ€é«˜çš„æ ·æœ¬
    top_uncertain_indices = np.argsort(uncertainty_scores)[-budget:]

    return [candidate_items[i] for i in top_uncertain_indices]
```

#### Reranking ä¸­çš„åé¦ˆæ•´åˆ

```python
def rerank_with_feedback(search_results, user_history, feedback_db):
    """
    åŸºäºç”¨æˆ·åé¦ˆé‡æ–°æ’åºæ£€ç´¢ç»“æœ

    æ­¥éª¤:
    1. è·å–åŸºç¡€ç›¸ä¼¼åº¦åˆ†æ•°
    2. åŠ å…¥ç”¨æˆ·å†å²åå¥½è°ƒæ•´
    3. åº”ç”¨å…¨å±€åé¦ˆç»Ÿè®¡
    4. Reciprocal Rank Fusion (RRF) èåˆ
    """
    reranked_results = []

    for result in search_results:
        base_score = result.similarity_score

        # ç”¨æˆ·ä¸ªæ€§åŒ–è°ƒæ•´
        user_preference = get_user_preference_score(result, user_history)

        # å…¨å±€åé¦ˆç»Ÿè®¡
        global_feedback = feedback_db.get_avg_rating(result.id)

        # åŠ æƒç»„åˆ
        final_score = (
            base_score * 0.5 +           # å‘é‡ç›¸ä¼¼åº¦
            user_preference * 0.3 +      # ä¸ªäººåå¥½
            global_feedback * 0.2        # ç¾¤ä½“æ™ºæ…§
        )

        result.final_score = final_score
        reranked_results.append(result)

    # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
    reranked_results.sort(key=lambda x: x.final_score, reverse=True)

    return reranked_results
```

---

## äºŒã€ä¸ªæ€§åŒ–çŸ¥è¯†åº“æ„å»ºæ–¹æ³•

### 2.1 å¤šæºæ•°æ®æ•´åˆç­–ç•¥

#### æ•°æ®æºåˆ†ç±»

| æ•°æ®æºç±»å‹ | ç¤ºä¾‹ | å¤„ç†æ–¹å¼ | æƒé‡å»ºè®® |
|-----------|------|---------|---------|
| **å¯¹è¯å†å²** | ä¸ AI çš„èŠå¤©è®°å½• | æå–å®ä½“ã€æ„å›¾ã€åå¥½ | é«˜ï¼ˆ0.9ï¼‰ |
| **ä¸ªäººæ–‡æ¡£** | ç¬”è®°ã€å¾…åŠäº‹é¡¹ã€æ—¥è®° | å…¨æ–‡ç´¢å¼•+å®ä½“æå– | é«˜ï¼ˆ0.85ï¼‰ |
| **è¡Œä¸ºæ•°æ®** | åº”ç”¨ä½¿ç”¨è®°å½•ã€æµè§ˆå†å² | éšå¼åå¥½æŒ–æ˜ | ä¸­ï¼ˆ0.6ï¼‰ |
| **å¤–éƒ¨çŸ¥è¯†** | ç½‘ç»œæ–‡ç« ã€API æ•°æ® | äº‹å®éªŒè¯åæ•´åˆ | ä½ï¼ˆ0.4ï¼‰ |
| **åé¦ˆæ ‡æ³¨** | ç”¨æˆ·æ˜¾å¼è¯„åˆ†/ä¿®æ­£ | ä½œä¸ºçœŸå€¼å¼ºåŒ–ä¿¡å· | æœ€é«˜ï¼ˆ1.0ï¼‰ |

#### ç»Ÿä¸€æ•°æ®æ¨¡å¼ï¼ˆSchemaï¼‰

```json
{
  "document_id": "uuid-12345",
  "source_type": "conversation|personal_note|web|feedback",
  "content": {
    "text": "åŸå§‹æ–‡æœ¬å†…å®¹",
    "structured_data": {
      "entities": ["äººå", "åœ°å", "äº‹ä»¶"],
      "relationships": [
        {"subject": "å®ä½“1", "predicate": "å…³ç³»", "object": "å®ä½“2"}
      ],
      "intent": "ç”¨æˆ·æ„å›¾åˆ†ç±»",
      "sentiment": 0.8
    }
  },
  "metadata": {
    "timestamp": "2025-01-14T10:30:00Z",
    "user_id": "user-001",
    "context": "è§¦å‘åœºæ™¯æè¿°",
    "quality_score": 0.85,
    "access_frequency": 12,
    "last_accessed": "2025-01-14T09:00:00Z"
  },
  "embeddings": {
    "dense_vector": [0.123, 0.456, ...],  // 768ç»´
    "sparse_vector": {"token_123": 0.8, "token_456": 0.6}  // BM25
  },
  "privacy_level": "private|shared|public",
  "expiration_date": "2026-01-14T00:00:00Z"  // å¯é€‰çš„æ•°æ®è¿‡æœŸ
}
```

#### æ•°æ®é¢„å¤„ç†ç®¡é“

```powershell
function Invoke-DataIngestionPipeline {
    <#
    .SYNOPSIS
        å¤šæºæ•°æ®æ‘„å…¥å’Œæ ‡å‡†åŒ–ç®¡é“

    .DESCRIPTION
        å¤„ç†ä¸åŒæ¥æºçš„æ•°æ®ï¼Œè½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼å¹¶ç”Ÿæˆå‘é‡åµŒå…¥
    #>
    [CmdletBinding()]
    param(
        [Parameter(Mandatory = $true)]
        [object]$RawData,

        [Parameter(Mandatory = $true)]
        [ValidateSet('conversation', 'personal_note', 'web', 'feedback')]
        [string]$SourceType
    )

    # 1. æ•°æ®æ¸…æ´—
    $CleanedData = Invoke-DataCleaning -Data $RawData

    # 2. å®ä½“å’Œå…³ç³»æå–
    $StructuredData = Invoke-EntityExtraction -Text $CleanedData.Text

    # 3. ç”ŸæˆåµŒå…¥å‘é‡
    $Embeddings = @{
        DenseVector = Get-DenseEmbedding -Text $CleanedData.Text -Model "text-embedding-3-small"
        SparseVector = Get-SparseEmbedding -Text $CleanedData.Text -Method "BM25"
    }

    # 4. è´¨é‡è¯„åˆ†
    $QualityScore = Get-ContentQualityScore -Content $CleanedData.Text -Source $SourceType

    # 5. æ„å»ºç»Ÿä¸€æ–‡æ¡£
    $Document = @{
        DocumentId = New-Guid
        SourceType = $SourceType
        Content = @{
            Text = $CleanedData.Text
            StructuredData = $StructuredData
        }
        Metadata = @{
            Timestamp = Get-Date
            QualityScore = $QualityScore.TotalScore
        }
        Embeddings = $Embeddings
    }

    return $Document
}
```

### 2.2 HybridRAG æ¶æ„è®¾è®¡

#### ä»€ä¹ˆæ˜¯ HybridRAGï¼Ÿ

**HybridRAG** ç»“åˆäº†ä¸¤ç§æ£€ç´¢æ–¹å¼ï¼š
1. **å‘é‡æ£€ç´¢ï¼ˆVectorRAGï¼‰**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„å¯†é›†å‘é‡æœç´¢
2. **çŸ¥è¯†å›¾è°±æ£€ç´¢ï¼ˆGraphRAGï¼‰**: åŸºäºå®ä½“å…³ç³»çš„ç»“æ„åŒ–æœç´¢

**æ ¸å¿ƒä¼˜åŠ¿**:
- å‘é‡æ£€ç´¢æä¾›å¹¿æ³›çš„è¯­ä¹‰åŒ¹é…
- çŸ¥è¯†å›¾è°±ä¿ç•™å¤æ‚å…³ç³»å’Œå…¨å±€ä¸Šä¸‹æ–‡
- æ··åˆæ£€ç´¢åœ¨å‡†ç¡®æ€§å’Œå¬å›ç‡ä¸Šä¼˜äºå•ä¸€æ–¹æ³•

#### HybridRAG æ¶æ„å›¾

```
ç”¨æˆ·æŸ¥è¯¢ï¼š"æœ€è¿‘æˆ‘å’Œå¼ ä¸‰è®¨è®ºçš„å…³äºé¡¹ç›® X çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æŸ¥è¯¢ç†è§£ä¸æ‰©å±•æ¨¡å—                       â”‚
â”‚  - å®ä½“è¯†åˆ«ï¼š[å¼ ä¸‰, é¡¹ç›®X]                        â”‚
â”‚  - æ„å›¾åˆ†ç±»ï¼šä¿¡æ¯æ£€ç´¢                             â”‚
â”‚  - æ—¶é—´èŒƒå›´ï¼šæœ€è¿‘ï¼ˆ30å¤©å†…ï¼‰                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ å‘é‡æ£€ç´¢     â”‚  â”‚ å›¾è°±æ£€ç´¢     â”‚  â”‚ ç¨€ç–æ£€ç´¢     â”‚
    â”‚ (å¯†é›†å‘é‡)   â”‚  â”‚ (å®ä½“+å…³ç³»)  â”‚  â”‚ (BM25)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚                 â”‚
           â”‚   Top-50 docs   â”‚   Subgraph      â”‚   Top-30 docs
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼                 â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      ç»“æœèåˆä¸é‡æ’åº           â”‚
            â”‚  - Reciprocal Rank Fusion      â”‚
            â”‚  - Cross-Encoder Reranking     â”‚
            â”‚  - ç”¨æˆ·åå¥½åŠ æƒ                â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Top-10 results
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      ä¸Šä¸‹æ–‡æ„å»ºä¸ç”Ÿæˆ           â”‚
            â”‚  - æ•´åˆæ£€ç´¢ç»“æœ                â”‚
            â”‚  - è°ƒç”¨ LLM ç”Ÿæˆå›ç­”           â”‚
            â”‚  - å¼•ç”¨æ¥æºæ ‡æ³¨                â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                   ç”¨æˆ·å›ç­” + åé¦ˆæ”¶é›†
```

#### å‘é‡æ£€ç´¢å®ç°

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

class VectorRetriever:
    def __init__(self, model_name="all-MiniLM-L6-v2", index_path="vector.index"):
        self.model = SentenceTransformer(model_name)
        self.index = faiss.read_index(index_path)

    def retrieve(self, query, top_k=50):
        """
        åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢æ–‡æ¡£
        """
        # æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.model.encode([query])

        # FAISS æ£€ç´¢
        distances, indices = self.index.search(query_embedding, top_k)

        results = []
        for idx, dist in zip(indices[0], distances[0]):
            results.append({
                'doc_id': idx,
                'similarity_score': 1 / (1 + dist),  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                'retrieval_method': 'vector'
            })

        return results
```

#### çŸ¥è¯†å›¾è°±æ£€ç´¢å®ç°

```python
from neo4j import GraphDatabase

class GraphRetriever:
    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def retrieve(self, entities, relationships=None, max_hops=2):
        """
        åŸºäºå®ä½“å’Œå…³ç³»æ£€ç´¢çŸ¥è¯†å­å›¾

        å‚æ•°:
            entities: æŸ¥è¯¢ä¸­çš„å®ä½“åˆ—è¡¨ ['å¼ ä¸‰', 'é¡¹ç›®X']
            relationships: å¯é€‰çš„å…³ç³»ç±»å‹è¿‡æ»¤
            max_hops: å›¾éå†çš„æœ€å¤§è·³æ•°
        """
        with self.driver.session() as session:
            query = """
            MATCH path = (start)-[*1..{max_hops}]-(end)
            WHERE start.name IN $entities
            RETURN path,
                   nodes(path) as nodes,
                   relationships(path) as rels
            ORDER BY length(path) ASC
            LIMIT 100
            """.format(max_hops=max_hops)

            result = session.run(query, entities=entities)

            subgraph_docs = []
            for record in result:
                # å°†å­å›¾è½¬æ¢ä¸ºæ–‡æœ¬æè¿°
                path_description = self._path_to_text(record['nodes'], record['rels'])
                subgraph_docs.append({
                    'content': path_description,
                    'retrieval_method': 'graph',
                    'hop_distance': len(record['rels'])
                })

            return subgraph_docs

    def _path_to_text(self, nodes, relationships):
        """
        å°†å›¾è·¯å¾„è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æè¿°
        """
        description_parts = []
        for i, rel in enumerate(relationships):
            start_node = nodes[i]
            end_node = nodes[i+1]
            description_parts.append(
                f"{start_node['name']} {rel.type} {end_node['name']}"
            )
        return "; ".join(description_parts)
```

#### æ··åˆæ£€ç´¢ä¸èåˆ

```python
from typing import List, Dict
import numpy as np

class HybridRetriever:
    def __init__(self, vector_retriever, graph_retriever, bm25_retriever=None):
        self.vector_retriever = vector_retriever
        self.graph_retriever = graph_retriever
        self.bm25_retriever = bm25_retriever

    def retrieve(self, query, entities=None, top_k=10):
        """
        æ··åˆæ£€ç´¢å¹¶èåˆç»“æœ
        """
        all_results = []

        # 1. å‘é‡æ£€ç´¢
        vector_results = self.vector_retriever.retrieve(query, top_k=50)
        all_results.extend(vector_results)

        # 2. çŸ¥è¯†å›¾è°±æ£€ç´¢ï¼ˆå¦‚æœæœ‰å®ä½“ï¼‰
        if entities:
            graph_results = self.graph_retriever.retrieve(entities)
            all_results.extend(graph_results)

        # 3. ç¨€ç–æ£€ç´¢ï¼ˆBM25ï¼‰
        if self.bm25_retriever:
            bm25_results = self.bm25_retriever.retrieve(query, top_k=30)
            all_results.extend(bm25_results)

        # 4. Reciprocal Rank Fusion (RRF)
        fused_results = self._reciprocal_rank_fusion(all_results)

        # 5. Cross-Encoder Reranking
        reranked_results = self._rerank_with_cross_encoder(query, fused_results, top_k)

        return reranked_results

    def _reciprocal_rank_fusion(self, results_list, k=60):
        """
        RRF èåˆå¤šè·¯æ£€ç´¢ç»“æœ

        å…¬å¼: score(d) = Î£ 1 / (k + rank_i(d))
        """
        doc_scores = {}

        # æŒ‰æ£€ç´¢æ–¹æ³•åˆ†ç»„
        methods = {}
        for result in results_list:
            method = result.get('retrieval_method', 'unknown')
            if method not in methods:
                methods[method] = []
            methods[method].append(result)

        # å¯¹æ¯ç§æ–¹æ³•çš„ç»“æœæ’åºå¹¶è®¡ç®— RRF åˆ†æ•°
        for method, results in methods.items():
            sorted_results = sorted(results,
                                   key=lambda x: x.get('similarity_score', 0),
                                   reverse=True)

            for rank, result in enumerate(sorted_results):
                doc_id = result['doc_id']
                rrf_score = 1 / (k + rank + 1)

                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'score': 0, 'methods': []}

                doc_scores[doc_id]['score'] += rrf_score
                doc_scores[doc_id]['methods'].append(method)

        # æ’åºå¹¶è¿”å›
        fused = sorted(doc_scores.items(),
                      key=lambda x: x[1]['score'],
                      reverse=True)

        return [{'doc_id': doc_id, 'rrf_score': data['score'], 'methods': data['methods']}
                for doc_id, data in fused]

    def _rerank_with_cross_encoder(self, query, candidates, top_k):
        """
        ä½¿ç”¨ Cross-Encoder æ¨¡å‹é‡æ’åº
        """
        from sentence_transformers import CrossEncoder

        model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

        # æ„å»º (query, document) å¯¹
        pairs = []
        for candidate in candidates[:50]:  # é™åˆ¶é‡æ’åºçš„å€™é€‰æ•°é‡
            doc_text = self._get_document_text(candidate['doc_id'])
            pairs.append([query, doc_text])

        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = model.predict(pairs)

        # é‡æ’åº
        reranked = sorted(zip(candidates[:50], scores),
                         key=lambda x: x[1],
                         reverse=True)[:top_k]

        return [{'doc_id': item[0]['doc_id'],
                 'rerank_score': float(item[1]),
                 'rrf_score': item[0]['rrf_score']}
                for item in reranked]

    def _get_document_text(self, doc_id):
        # ä»æ•°æ®åº“è·å–æ–‡æ¡£æ–‡æœ¬
        pass
```

### 2.3 ä¸ªäººåå¥½æ¨¡å‹æ„å»º

#### ç”¨æˆ·ç”»åƒï¼ˆUser Profileï¼‰æ„å»º

```python
class UserPreferenceModel:
    """
    ä¸ªäººåå¥½æ¨¡å‹ï¼šä»å†å²äº¤äº’ä¸­å­¦ä¹ ç”¨æˆ·åå¥½
    """
    def __init__(self, user_id):
        self.user_id = user_id
        self.preference_vector = None  # ç”¨æˆ·åå¥½çš„å¯†é›†å‘é‡è¡¨ç¤º
        self.entity_preferences = {}   # å®ä½“çº§åˆ«çš„åå¥½
        self.topic_interests = {}      # ä¸»é¢˜å…´è¶£åˆ†å¸ƒ
        self.interaction_history = []  # äº¤äº’å†å²

    def update_from_feedback(self, feedback_data):
        """
        ä»ç”¨æˆ·åé¦ˆä¸­æ›´æ–°åå¥½æ¨¡å‹

        å‚æ•°:
            feedback_data: {
                'doc_id': æ–‡æ¡£ID,
                'rating': è¯„åˆ†(1-5),
                'implicit_signals': {
                    'read_time': é˜…è¯»æ—¶é—´ç§’æ•°,
                    'copied': æ˜¯å¦å¤åˆ¶,
                    'shared': æ˜¯å¦åˆ†äº«
                },
                'timestamp': æ—¶é—´æˆ³
            }
        """
        # 1. æ›´æ–°äº¤äº’å†å²
        self.interaction_history.append(feedback_data)

        # 2. æå–æ–‡æ¡£ç‰¹å¾
        doc_features = self._extract_document_features(feedback_data['doc_id'])

        # 3. è®¡ç®—åé¦ˆæƒé‡
        feedback_weight = self._calculate_feedback_weight(feedback_data)

        # 4. æ›´æ–°åå¥½å‘é‡ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
        if self.preference_vector is None:
            self.preference_vector = doc_features
        else:
            alpha = 0.1  # å­¦ä¹ ç‡
            self.preference_vector = (
                (1 - alpha) * self.preference_vector +
                alpha * feedback_weight * doc_features
            )

        # 5. æ›´æ–°å®ä½“åå¥½
        for entity in doc_features['entities']:
            if entity not in self.entity_preferences:
                self.entity_preferences[entity] = 0
            self.entity_preferences[entity] += feedback_weight

        # 6. æ›´æ–°ä¸»é¢˜å…´è¶£
        for topic, score in doc_features['topics'].items():
            if topic not in self.topic_interests:
                self.topic_interests[topic] = 0
            self.topic_interests[topic] += feedback_weight * score

    def _calculate_feedback_weight(self, feedback_data):
        """
        ç»¼åˆæ˜¾å¼å’Œéšå¼ä¿¡å·è®¡ç®—åé¦ˆæƒé‡
        """
        # æ˜¾å¼è¯„åˆ†ï¼ˆ1-5ï¼‰å½’ä¸€åŒ–
        explicit_weight = (feedback_data.get('rating', 3) - 1) / 4

        # éšå¼ä¿¡å·
        implicit = feedback_data.get('implicit_signals', {})

        # é˜…è¯»æ—¶é—´ï¼ˆå‡è®¾æ­£å¸¸é˜…è¯»é€Ÿåº¦ 200å­—/åˆ†é’Ÿï¼‰
        expected_read_time = len(feedback_data.get('content', '')) / 200 * 60
        actual_read_time = implicit.get('read_time', 0)
        read_completion = min(actual_read_time / expected_read_time, 1.5)

        # å…¶ä»–è¡Œä¸º
        copied = 1.2 if implicit.get('copied') else 1.0
        shared = 1.5 if implicit.get('shared') else 1.0

        # ç»¼åˆæƒé‡
        final_weight = (
            explicit_weight * 0.6 +          # æ˜¾å¼è¯„åˆ†å 60%
            (read_completion - 1) * 0.2 +    # é˜…è¯»å®Œæˆåº¦å 20%
            (copied - 1) * 0.1 +             # å¤åˆ¶è¡Œä¸ºå 10%
            (shared - 1) * 0.1               # åˆ†äº«è¡Œä¸ºå 10%
        )

        # æ—¶é—´è¡°å‡
        days_ago = (datetime.now() - feedback_data['timestamp']).days
        time_weight = np.exp(-0.01 * days_ago)

        return final_weight * time_weight

    def personalized_rerank(self, search_results):
        """
        åŸºäºç”¨æˆ·åå¥½é‡æ’åºæ£€ç´¢ç»“æœ
        """
        if self.preference_vector is None:
            return search_results  # å†·å¯åŠ¨ï¼šæ— ä¸ªæ€§åŒ–

        reranked = []
        for result in search_results:
            doc_features = self._extract_document_features(result['doc_id'])

            # è®¡ç®—ä¸ç”¨æˆ·åå¥½å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
            personalization_score = cosine_similarity(
                self.preference_vector,
                doc_features['embedding']
            )

            # å®ä½“åŒ¹é…åŠ åˆ†
            entity_bonus = sum(
                self.entity_preferences.get(e, 0)
                for e in doc_features['entities']
            ) / max(len(doc_features['entities']), 1)

            # ä¸»é¢˜åŒ¹é…åŠ åˆ†
            topic_bonus = sum(
                self.topic_interests.get(t, 0) * score
                for t, score in doc_features['topics'].items()
            )

            # æœ€ç»ˆåˆ†æ•° = åŸå§‹åˆ†æ•° Ã— (1 + ä¸ªæ€§åŒ–è°ƒæ•´)
            personalized_score = result['score'] * (
                1 + 0.3 * personalization_score +
                0.1 * entity_bonus +
                0.1 * topic_bonus
            )

            reranked.append({
                **result,
                'personalized_score': personalized_score,
                'personalization_boost': personalized_score - result['score']
            })

        return sorted(reranked, key=lambda x: x['personalized_score'], reverse=True)
```

### 2.4 å¯¹è¯è®°å¿†ç®¡ç†

#### è®°å¿†å±‚æ¬¡ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              çŸ­æœŸè®°å¿† (Short-term Memory)            â”‚
â”‚  - å½“å‰ä¼šè¯çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆæœ€è¿‘ N è½®å¯¹è¯ï¼‰             â”‚
â”‚  - å®ç°ï¼šæ»šåŠ¨ç¼“å†²åŒº                                 â”‚
â”‚  - å®¹é‡ï¼šæœ€è¿‘ 10-20 è½®å¯¹è¯                          â”‚
â”‚  - å­˜å‚¨ï¼šå†…å­˜ä¸­                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å·¥ä½œè®°å¿† (Working Memory)               â”‚
â”‚  - å½“å‰ä»»åŠ¡ç›¸å…³çš„æ‰€æœ‰ä¸Šä¸‹æ–‡                         â”‚
â”‚  - å®ç°ï¼šå‘é‡æ£€ç´¢ + å…³é”®ä¿¡æ¯æå–                    â”‚
â”‚  - å®¹é‡ï¼šæœ€è¿‘ 1-7 å¤©çš„ç›¸å…³å¯¹è¯                      â”‚
â”‚  - å­˜å‚¨ï¼šå‘é‡æ•°æ®åº“                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            é•¿æœŸè®°å¿† (Long-term Memory)               â”‚
â”‚  - è·¨ä¼šè¯çš„æŒä¹…åŒ–çŸ¥è¯†å’Œåå¥½                         â”‚
â”‚  - å®ç°ï¼šçŸ¥è¯†å›¾è°± + å‘é‡ç´¢å¼•                        â”‚
â”‚  - å®¹é‡ï¼šæ‰€æœ‰å†å²æ•°æ®ï¼ˆæœ‰æ—¶é—´è¡°å‡æƒé‡ï¼‰             â”‚
â”‚  - å­˜å‚¨ï¼šæ•°æ®åº“ + çŸ¥è¯†å›¾è°±                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### LangChain è®°å¿†ç®¡ç†å®ç°

```python
from langchain.memory import ConversationBufferWindowMemory
from langchain_community.chat_message_histories import SQLChatMessageHistory
from langchain.schema import HumanMessage, AIMessage

class PersonalizedConversationMemory:
    """
    ç»“åˆçŸ­æœŸã€å·¥ä½œå’Œé•¿æœŸè®°å¿†çš„å¯¹è¯ç®¡ç†ç³»ç»Ÿ
    """
    def __init__(self, user_id, session_id):
        self.user_id = user_id
        self.session_id = session_id

        # çŸ­æœŸè®°å¿†ï¼šæœ€è¿‘ 10 è½®å¯¹è¯
        self.short_term = ConversationBufferWindowMemory(
            k=10,  # ä¿ç•™æœ€è¿‘10è½®
            return_messages=True,
            memory_key="chat_history"
        )

        # å·¥ä½œè®°å¿†ï¼šå½“å‰ä¼šè¯çš„æŒä¹…åŒ–å­˜å‚¨
        self.working_memory = SQLChatMessageHistory(
            session_id=session_id,
            connection_string="sqlite:///chat_history.db"
        )

        # é•¿æœŸè®°å¿†ï¼šå‘é‡æ•°æ®åº“ + çŸ¥è¯†å›¾è°±
        self.long_term_vector = ChromaDB(collection_name=f"user_{user_id}_memory")
        self.long_term_graph = Neo4jGraph(uri="bolt://localhost:7687")

    def add_exchange(self, user_message, ai_response, metadata=None):
        """
        æ·»åŠ ä¸€è½®å¯¹è¯åˆ°æ‰€æœ‰è®°å¿†å±‚
        """
        # 1. çŸ­æœŸè®°å¿†ï¼ˆå†…å­˜ï¼‰
        self.short_term.save_context(
            {"input": user_message},
            {"output": ai_response}
        )

        # 2. å·¥ä½œè®°å¿†ï¼ˆSQLï¼‰
        self.working_memory.add_user_message(user_message)
        self.working_memory.add_ai_message(ai_response)

        # 3. é•¿æœŸè®°å¿†ï¼ˆå‘é‡åŒ–å¹¶å­˜å‚¨ï¼‰
        self._store_in_long_term_memory(user_message, ai_response, metadata)

    def _store_in_long_term_memory(self, user_message, ai_response, metadata):
        """
        å°†å¯¹è¯å­˜å…¥é•¿æœŸè®°å¿†ï¼ˆå‘é‡DB + çŸ¥è¯†å›¾è°±ï¼‰
        """
        # å‘é‡åŒ–å¯¹è¯
        conversation_text = f"User: {user_message}\nAI: {ai_response}"
        embedding = self._get_embedding(conversation_text)

        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        self.long_term_vector.add(
            documents=[conversation_text],
            embeddings=[embedding],
            metadatas=[{
                'user_id': self.user_id,
                'session_id': self.session_id,
                'timestamp': datetime.now().isoformat(),
                **(metadata or {})
            }],
            ids=[f"{self.session_id}_{uuid.uuid4()}"]
        )

        # æå–å®ä½“å’Œå…³ç³»ï¼Œå­˜å…¥çŸ¥è¯†å›¾è°±
        entities = self._extract_entities(conversation_text)
        self._update_knowledge_graph(entities)

    def retrieve_relevant_memory(self, current_query, k=5):
        """
        ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³å†å²å¯¹è¯
        """
        # å‘é‡æ£€ç´¢
        query_embedding = self._get_embedding(current_query)
        relevant_conversations = self.long_term_vector.query(
            query_embeddings=[query_embedding],
            n_results=k,
            where={"user_id": self.user_id}
        )

        # çŸ¥è¯†å›¾è°±æ£€ç´¢ï¼ˆå®ä½“ç›¸å…³ï¼‰
        entities_in_query = self._extract_entities(current_query)
        related_facts = self._query_knowledge_graph(entities_in_query)

        return {
            'relevant_conversations': relevant_conversations,
            'related_facts': related_facts
        }

    def get_full_context(self, current_query):
        """
        æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼šçŸ­æœŸ + ç›¸å…³é•¿æœŸè®°å¿†
        """
        # çŸ­æœŸè®°å¿†ï¼ˆæœ€è¿‘å¯¹è¯ï¼‰
        recent_context = self.short_term.load_memory_variables({})

        # é•¿æœŸè®°å¿†ï¼ˆç›¸å…³å†å²ï¼‰
        relevant_memory = self.retrieve_relevant_memory(current_query)

        # ç»„åˆä¸Šä¸‹æ–‡
        full_context = {
            'recent_conversation': recent_context['chat_history'],
            'relevant_history': relevant_memory['relevant_conversations'],
            'knowledge_facts': relevant_memory['related_facts']
        }

        return full_context
```

#### è®°å¿†å‹ç¼©ä¸æ‘˜è¦

å¯¹äºé•¿æœŸå¯¹è¯ï¼Œä½¿ç”¨æ‘˜è¦æŠ€æœ¯å‹ç¼©å†å²ä¸Šä¸‹æ–‡ï¼š

```python
from langchain.chains.summarize import load_summarize_chain
from langchain_openai import ChatOpenAI

class MemoryCompressor:
    """
    å¯¹è¯è®°å¿†å‹ç¼©å™¨ï¼šå°†é•¿å¯¹è¯å‹ç¼©ä¸ºæ‘˜è¦
    """
    def __init__(self):
        self.llm = ChatOpenAI(temperature=0, model="gpt-4o-mini")
        self.summarize_chain = load_summarize_chain(
            self.llm,
            chain_type="map_reduce"
        )

    def compress_conversation_history(self, messages, max_tokens=500):
        """
        å°†é•¿å¯¹è¯å†å²å‹ç¼©ä¸ºç®€æ´æ‘˜è¦

        ç­–ç•¥:
        1. å¦‚æœå¯¹è¯ < max_tokensï¼Œç›´æ¥è¿”å›
        2. å¦åˆ™ï¼Œä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        """
        total_tokens = sum(len(m.content.split()) for m in messages)

        if total_tokens <= max_tokens:
            return messages

        # æ„å»ºæ–‡æ¡£åˆ—è¡¨
        docs = [Document(page_content=m.content) for m in messages]

        # ç”Ÿæˆæ‘˜è¦
        summary = self.summarize_chain.run(docs)

        # ä¿ç•™æœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯ + æ‘˜è¦
        return [
            AIMessage(content=f"[å¯¹è¯æ‘˜è¦]: {summary}"),
            *messages[-3:]  # ä¿ç•™æœ€è¿‘3æ¡
        ]
```

---

## ä¸‰ã€æŠ€æœ¯æ–¹æ¡ˆä¸å®ç°å»ºè®®

### 3.1 æ¨èæŠ€æœ¯æ ˆ

#### æ ¸å¿ƒç»„ä»¶é€‰å‹

| ç»„ä»¶ç±»åˆ« | æ¨èæŠ€æœ¯ | ç†ç”± |
|---------|---------|------|
| **å‘é‡æ•°æ®åº“** | **Weaviate** æˆ– **Qdrant** | â€¢ æ”¯æŒæ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25ï¼‰<br>â€¢ åŸç”Ÿ reranking æ”¯æŒ<br>â€¢ å¤šç§Ÿæˆ·éš”ç¦»<br>â€¢ æ´»è·ƒç¤¾åŒº |
| **çŸ¥è¯†å›¾è°±** | **Neo4j** | â€¢ æˆç†Ÿçš„å›¾æ•°æ®åº“<br>â€¢ å¼ºå¤§çš„æŸ¥è¯¢è¯­è¨€ï¼ˆCypherï¼‰<br>â€¢ è‰¯å¥½çš„å¯è§†åŒ–å·¥å…· |
| **åµŒå…¥æ¨¡å‹** | **text-embedding-3-small** (OpenAI) æˆ– **all-MiniLM-L6-v2** (å¼€æº) | â€¢ æ€§èƒ½ä¸æˆæœ¬å¹³è¡¡<br>â€¢ å¹¿æ³›ä½¿ç”¨å’ŒéªŒè¯ |
| **Reranker** | **cross-encoder/ms-marco-MiniLM-L-6-v2** | â€¢ è½»é‡çº§ä½†å‡†ç¡®<br>â€¢ ä½å»¶è¿Ÿï¼ˆ<2ç§’ï¼‰<br>â€¢ ç¦»çº¿å¯éƒ¨ç½² |
| **LLM** | **Ollama (æœ¬åœ°)** æˆ– **GPT-4o-mini (äº‘ç«¯)** | â€¢ é¡¹ç›®å·²ä½¿ç”¨ Ollama<br>â€¢ å¯é€‰äº‘ç«¯å¢å¼º |
| **RAG æ¡†æ¶** | **LangChain** + **LangGraph** | â€¢ å®Œæ•´çš„è®°å¿†ç®¡ç†<br>â€¢ çµæ´»çš„å·¥ä½œæµç¼–æ’<br>â€¢ ä¸°å¯Œçš„é›†æˆ |
| **åé¦ˆå­˜å‚¨** | **PostgreSQL** (å…³ç³»æ•°æ®) + **Qdrant** (å‘é‡) | â€¢ ç»“æ„åŒ–åé¦ˆç”¨ SQL<br>â€¢ å‘é‡åŒ–åé¦ˆç”¨å‘é‡DB |

#### ä¸ºä½•é€‰æ‹© Weaviate/Qdrantï¼Ÿ

**Weaviate ä¼˜åŠ¿**:
```yaml
ç‰¹æ€§:
  - åŸç”Ÿæ··åˆæ£€ç´¢: å•æ¬¡æŸ¥è¯¢åŒæ—¶ä½¿ç”¨å‘é‡+BM25
  - è‡ªåŠ¨ reranking: å†…ç½® cross-encoder é‡æ’åº
  - æ¨¡å—åŒ–æ¶æ„: æ”¯æŒå¤šç§å‘é‡åŒ–æ¨¡å‹å’Œ reranker
  - å¤šç§Ÿæˆ·: é€‚åˆæœªæ¥å¤šç”¨æˆ·æ‰©å±•
  - GraphQL API: çµæ´»çš„æŸ¥è¯¢æ¥å£

ç¤ºä¾‹æŸ¥è¯¢:
  Get:
    Document:
      nearText: {concepts: ["é¡¹ç›®è®¨è®º"]}
      bm25: {query: "å¼ ä¸‰"}
      limit: 10
      rerank: {property: "content", query: "æœ€è¿‘çš„é—®é¢˜"}
```

**Qdrant ä¼˜åŠ¿**:
```python
# é«˜æ€§èƒ½è¿‡æ»¤
qdrant_client.search(
    collection_name="personal_kb",
    query_vector=query_embedding,
    query_filter=Filter(
        must=[
            FieldCondition(
                key="user_id",
                match=MatchValue(value="user-001")
            ),
            FieldCondition(
                key="timestamp",
                range=DateTimeRange(
                    gte=datetime.now() - timedelta(days=30)
                )
            )
        ]
    ),
    limit=50,
    with_payload=True
)

# ä¼˜åŠ¿ï¼š
# - æé«˜çš„æŸ¥è¯¢æ€§èƒ½ï¼ˆRust ç¼–å†™ï¼‰
# - çµæ´»çš„è¿‡æ»¤æ¡ä»¶
# - æ”¯æŒç¨€ç–å‘é‡ï¼ˆBM25ï¼‰
# - äº‘åŸç”Ÿæ¶æ„
```

### 3.2 å®ç°è·¯çº¿å›¾

#### Phase 1: åŸºç¡€ RAG + ç®€å•åé¦ˆï¼ˆ2-3å‘¨ï¼‰

**ç›®æ ‡**: å»ºç«‹åŸºæœ¬çš„å‘é‡æ£€ç´¢å’Œåé¦ˆæ”¶é›†æœºåˆ¶

```
Week 1-2: åŸºç¡€è®¾æ–½æ­å»º
  âœ“ å®‰è£…å’Œé…ç½® Qdrant/Weaviate
  âœ“ è®¾ç½® PostgreSQL å­˜å‚¨ç»“æ„åŒ–æ•°æ®
  âœ“ å®ç°æ•°æ®æ‘„å…¥ç®¡é“ï¼ˆå¯¹è¯å†å² -> å‘é‡åŒ– -> å­˜å‚¨ï¼‰
  âœ“ åŸºç¡€å‘é‡æ£€ç´¢åŠŸèƒ½

Week 2-3: åé¦ˆç³»ç»Ÿ v1
  âœ“ å®ç°æ˜¾å¼åé¦ˆæ¥å£ï¼ˆğŸ‘/ğŸ‘ï¼‰
  âœ“ æ”¶é›†éšå¼åé¦ˆï¼ˆæ’­æ”¾æ—¶é•¿ã€é‡æ’­æ¬¡æ•°ï¼‰
  âœ“ åé¦ˆæ•°æ®å­˜å‚¨åˆ° PostgreSQL
  âœ“ ç®€å•çš„åé¦ˆç»Ÿè®¡æŠ¥å‘Š
```

**äº¤ä»˜ç‰©**:
- å¯ç”¨çš„å‘é‡æ£€ç´¢ API
- åŸºç¡€åé¦ˆæ”¶é›†ç•Œé¢
- åé¦ˆæ•°æ®çš„ SQL schema

#### Phase 2: è´¨é‡æ§åˆ¶ + HybridRAGï¼ˆ3-4å‘¨ï¼‰

**ç›®æ ‡**: å¢å¼ºæ£€ç´¢è´¨é‡å’Œé˜²æ­¢æ•°æ®æ±¡æŸ“

```
Week 4-5: è´¨é‡æ§åˆ¶
  âœ“ å®ç°è‡ªåŠ¨è´¨é‡è¯„åˆ†æ¨¡å‹
  âœ“ è®¾ç½®å…¥åº“é˜ˆå€¼å’Œåˆ†å±‚ç­–ç•¥
  âœ“ æ·»åŠ äººå·¥å®¡æ ¸é˜Ÿåˆ—
  âœ“ å¼‚å¸¸æ£€æµ‹å’Œæ•°æ®æ¼‚ç§»ç›‘æ§

Week 6-7: HybridRAG
  âœ“ æ·»åŠ  BM25 ç¨€ç–æ£€ç´¢
  âœ“ å®ç° Reciprocal Rank Fusion
  âœ“ é›†æˆ Cross-Encoder Reranking
  âœ“ æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–
```

**äº¤ä»˜ç‰©**:
- è´¨é‡æ§åˆ¶ç®¡é“
- æ··åˆæ£€ç´¢ç³»ç»Ÿ
- Reranking æ¨¡å—

#### Phase 3: çŸ¥è¯†å›¾è°± + ä¸ªæ€§åŒ–ï¼ˆ4-5å‘¨ï¼‰

**ç›®æ ‡**: æ„å»ºçŸ¥è¯†å›¾è°±å’Œä¸ªæ€§åŒ–åå¥½æ¨¡å‹

```
Week 8-9: çŸ¥è¯†å›¾è°±æ„å»º
  âœ“ å®‰è£…å’Œé…ç½® Neo4j
  âœ“ å®ä½“å’Œå…³ç³»æå–ç®¡é“
  âœ“ è‡ªåŠ¨åŒ–å›¾è°±æ›´æ–°
  âœ“ å›¾è°±å¯è§†åŒ–ç•Œé¢

Week 10-11: ä¸ªæ€§åŒ–å¼•æ“
  âœ“ ç”¨æˆ·åå¥½æ¨¡å‹å®ç°
  âœ“ ä¸ªæ€§åŒ– reranking
  âœ“ A/B æµ‹è¯•æ¡†æ¶
  âœ“ åå¥½å­¦ä¹ åé¦ˆå¾ªç¯

Week 12: æ•´åˆä¸ä¼˜åŒ–
  âœ“ æ‰€æœ‰ç»„ä»¶é›†æˆæµ‹è¯•
  âœ“ æ€§èƒ½ä¼˜åŒ–ï¼ˆå»¶è¿Ÿ < 2ç§’ï¼‰
  âœ“ æ–‡æ¡£å’Œè¿ç»´æ‰‹å†Œ
```

**äº¤ä»˜ç‰©**:
- å®Œæ•´çš„ HybridRAG ç³»ç»Ÿ
- ä¸ªæ€§åŒ–å¼•æ“
- çŸ¥è¯†å›¾è°±å¯è§†åŒ–

#### Phase 4: RLHF + é«˜çº§ç‰¹æ€§ï¼ˆæŒç»­è¿­ä»£ï¼‰

**ç›®æ ‡**: å¼•å…¥å¼ºåŒ–å­¦ä¹ å’ŒæŒç»­æ”¹è¿›æœºåˆ¶

```
é•¿æœŸæ”¹è¿›:
  âœ“ RLHF å¥–åŠ±æ¨¡å‹è®­ç»ƒ
  âœ“ ä¸»åŠ¨å­¦ä¹ æ ·æœ¬é€‰æ‹©
  âœ“ å¤šæ¨¡æ€æ”¯æŒï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ï¼‰
  âœ“ è·¨è¯­è¨€çŸ¥è¯†åº“
  âœ“ è”é‚¦å­¦ä¹ ï¼ˆéšç§ä¿æŠ¤ï¼‰
```

### 3.3 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### å»¶è¿Ÿä¼˜åŒ–

```python
# ç›®æ ‡ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿ < 2ç§’

# 1. å‘é‡æ£€ç´¢ä¼˜åŒ–ï¼ˆç›®æ ‡ <300msï¼‰
- ä½¿ç”¨ HNSW ç´¢å¼•ï¼ˆè€Œéæš´åŠ›æœç´¢ï¼‰
- è®¾ç½®åˆç†çš„ ef_search å‚æ•°ï¼ˆå¹³è¡¡é€Ÿåº¦å’Œå¬å›ç‡ï¼‰
- é¢„çƒ­ç´¢å¼•åˆ°å†…å­˜

# 2. Reranking ä¼˜åŒ–ï¼ˆç›®æ ‡ <1ç§’ï¼‰
- é™åˆ¶ rerank å€™é€‰æ•°é‡ï¼ˆ50ä¸ªè€Œé200ä¸ªï¼‰
- ä½¿ç”¨è½»é‡çº§ cross-encoderï¼ˆMiniLM è€Œé BERT-largeï¼‰
- æ‰¹é‡æ¨ç†è€Œéé€ä¸ª

# 3. LLM ç”Ÿæˆä¼˜åŒ–ï¼ˆç›®æ ‡ <1ç§’ for 100 tokensï¼‰
- ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆSSEï¼‰
- å¯ç”¨ prompt cachingï¼ˆAnthropicï¼‰
- è€ƒè™‘é‡åŒ–æ¨¡å‹ï¼ˆ8-bit/4-bitï¼‰

# 4. ç¼“å­˜ç­–ç•¥
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_cached_embedding(text):
    return embedding_model.encode(text)

# å¸¸è§æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆRedisï¼‰
redis_client.setex(
    key=f"query:{query_hash}",
    time=3600,  # 1å°æ—¶è¿‡æœŸ
    value=json.dumps(results)
)
```

#### æˆæœ¬ä¼˜åŒ–

```python
# 1. åµŒå…¥æ¨¡å‹é€‰æ‹©
# text-embedding-3-small: $0.02 / 1M tokens
# all-MiniLM-L6-v2 (æœ¬åœ°): å…è´¹ä½†éœ€è‡ªè¡Œæ‰˜ç®¡

# 2. LLM è°ƒç”¨ä¼˜åŒ–
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆGPT-4o-mini è€Œé GPT-4ï¼‰
- å¯ç”¨ prompt cachingï¼ˆèŠ‚çœ 90% æˆæœ¬ï¼‰
- æ‰¹é‡å¤„ç†è¯·æ±‚

# 3. å‘é‡æ•°æ®åº“å­˜å‚¨
- å®šæœŸæ¸…ç†ä½è´¨é‡/è¿‡æœŸæ•°æ®
- ä½¿ç”¨é‡åŒ–å‘é‡ï¼ˆPQ/SQï¼‰å‡å°‘å­˜å‚¨
- å¯¹å†·æ•°æ®ä½¿ç”¨å¯¹è±¡å­˜å‚¨ï¼ˆS3ï¼‰

# æˆæœ¬ç›‘æ§
class CostTracker:
    def __init__(self):
        self.costs = {
            'embeddings': 0,
            'llm_calls': 0,
            'vector_db_storage': 0
        }

    def track_embedding_cost(self, num_tokens):
        cost = (num_tokens / 1_000_000) * 0.02
        self.costs['embeddings'] += cost

    def track_llm_cost(self, input_tokens, output_tokens):
        # GPT-4o-mini å®šä»·
        input_cost = (input_tokens / 1_000_000) * 0.15
        output_cost = (output_tokens / 1_000_000) * 0.60
        self.costs['llm_calls'] += (input_cost + output_cost)
```

#### è´¨é‡è¯„ä¼°æŒ‡æ ‡

```python
# RAG ç³»ç»Ÿè¯„ä¼°æ¡†æ¶

class RAGEvaluator:
    def __init__(self):
        self.metrics = {}

    def evaluate(self, queries, ground_truth):
        """
        è¯„ä¼° RAG ç³»ç»Ÿæ€§èƒ½

        æ ¸å¿ƒæŒ‡æ ‡:
        1. Faithfulness (äº‹å®ä¸€è‡´æ€§): ç”Ÿæˆå†…å®¹ä¸æ£€ç´¢å†…å®¹çš„ä¸€è‡´æ€§
        2. Answer Relevance (ç­”æ¡ˆç›¸å…³æ€§): ç­”æ¡ˆä¸æŸ¥è¯¢çš„åŒ¹é…åº¦
        3. Context Precision (ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦): æ£€ç´¢å†…å®¹çš„ç›¸å…³æ€§
        4. Context Recall (ä¸Šä¸‹æ–‡å¬å›ç‡): æ£€ç´¢æ˜¯å¦è¦†ç›–æ‰€éœ€ä¿¡æ¯
        """

        faithfulness_scores = []
        relevance_scores = []

        for query, gt in zip(queries, ground_truth):
            # æ‰§è¡Œ RAG
            retrieved_docs = self.retriever.retrieve(query)
            generated_answer = self.generator.generate(query, retrieved_docs)

            # 1. Faithfulness: æ£€æŸ¥ç”Ÿæˆå†…å®¹æ˜¯å¦åŸºäºæ£€ç´¢å†…å®¹
            faithfulness = self._check_faithfulness(generated_answer, retrieved_docs)
            faithfulness_scores.append(faithfulness)

            # 2. Answer Relevance: ç­”æ¡ˆä¸æŸ¥è¯¢çš„ç›¸å…³æ€§
            relevance = self._check_relevance(generated_answer, query)
            relevance_scores.append(relevance)

        self.metrics = {
            'avg_faithfulness': np.mean(faithfulness_scores),
            'avg_relevance': np.mean(relevance_scores),
            'retrieval_latency': np.mean(self.retrieval_times),
            'generation_latency': np.mean(self.generation_times)
        }

        return self.metrics

    def _check_faithfulness(self, answer, docs):
        """
        ä½¿ç”¨ NLI æ¨¡å‹æ£€æŸ¥äº‹å®ä¸€è‡´æ€§
        """
        from transformers import pipeline
        nli_model = pipeline("text-classification",
                            model="microsoft/deberta-large-mnli")

        # å°†ç­”æ¡ˆçš„æ¯ä¸ªå£°æ˜ä¸æ–‡æ¡£è¿›è¡Œè•´å«æ£€æŸ¥
        claims = self._extract_claims(answer)
        entailment_scores = []

        for claim in claims:
            context = " ".join([doc['content'] for doc in docs])
            result = nli_model(f"{context} </s> {claim}")

            # æ£€æŸ¥æ˜¯å¦ä¸º entailmentï¼ˆè•´å«ï¼‰
            entailment_score = [
                r['score'] for r in result if r['label'] == 'ENTAILMENT'
            ][0]
            entailment_scores.append(entailment_score)

        return np.mean(entailment_scores)
```

---

## å››ã€å‚è€ƒèµ„æºä¸å¼€æºé¡¹ç›®

### 4.1 æ ¸å¿ƒå­¦æœ¯è®ºæ–‡

#### RLHF ä¸åé¦ˆæœºåˆ¶

1. **"Training Language Models to Follow Instructions with Human Feedback"** (InstructGPT, OpenAI, 2022)
   - é“¾æ¥: https://arxiv.org/abs/2203.02155
   - æ ¸å¿ƒè´¡çŒ®: RLHF çš„æ ‡å‡†æµç¨‹å®šä¹‰
   - åº”ç”¨: å¦‚ä½•æ”¶é›†äººç±»åå¥½æ•°æ®å¹¶è®­ç»ƒå¥–åŠ±æ¨¡å‹

2. **"Constitutional AI: Harmlessness from AI Feedback"** (Anthropic, 2022)
   - é“¾æ¥: https://arxiv.org/abs/2212.08073
   - æ ¸å¿ƒè´¡çŒ®: ä½¿ç”¨ AI åé¦ˆå‡å°‘äººå·¥æ ‡æ³¨æˆæœ¬
   - åº”ç”¨: è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶æœºåˆ¶

3. **"RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback"** (CVPR 2024)
   - GitHub: https://github.com/RLHF-V/RLHF-V
   - æ ¸å¿ƒè´¡çŒ®: ç»†ç²’åº¦çš„å¤šç»´åº¦åé¦ˆæœºåˆ¶
   - åº”ç”¨: å¤šç»´è´¨é‡è¯„åˆ†ç³»ç»Ÿè®¾è®¡

#### RAG ä¸ä¸ªæ€§åŒ–

4. **"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"** (Meta AI, 2020)
   - é“¾æ¥: https://arxiv.org/abs/2005.11401
   - æ ¸å¿ƒè´¡çŒ®: RAG çš„åŸå§‹å®šä¹‰å’Œæ¶æ„
   - åº”ç”¨: RAG åŸºç¡€å®ç°

5. **"HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction"** (2024)
   - é“¾æ¥: https://arxiv.org/abs/2408.04948
   - æ ¸å¿ƒè´¡çŒ®: å‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±çš„æ··åˆæ–¹æ¡ˆ
   - åº”ç”¨: æœ¬æŠ¥å‘Šæ¨èçš„ HybridRAG æ¶æ„

6. **"A Survey of Personalization: From RAG to Agent"** (2025)
   - é“¾æ¥: https://arxiv.org/abs/2504.10147
   - GitHub: https://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent
   - æ ¸å¿ƒè´¡çŒ®: å…¨é¢çš„ä¸ªæ€§åŒ– RAG ç»¼è¿°
   - åº”ç”¨: ä¸ªæ€§åŒ–ç­–ç•¥é€‰æ‹©æŒ‡å—

7. **"Contextual Retrieval"** (Anthropic, 2024)
   - é“¾æ¥: https://www.anthropic.com/news/contextual-retrieval
   - æ ¸å¿ƒè´¡çŒ®: åœ¨å—åµŒå…¥å‰æ·»åŠ ä¸Šä¸‹æ–‡è§£é‡Š
   - åº”ç”¨: æå‡æ£€ç´¢ç²¾åº¦ 35%

### 4.2 å¼€æºé¡¹ç›®ä¸å·¥å…·

#### å®Œæ•´ RAG æ¡†æ¶

1. **RAGFlow** (InfiniFlow)
   - GitHub: https://github.com/infiniflow/ragflow
   - Star: 20k+
   - ç‰¹ç‚¹:
     - æ·±åº¦æ–‡æ¡£ç†è§£ï¼ˆOCRã€è¡¨æ ¼ã€å…¬å¼ï¼‰
     - å¯è§†åŒ–å·¥ä½œæµç¼–æ’
     - ç”Ÿäº§çº§éƒ¨ç½²
   - é€‚ç”¨: ä¼ä¸šçº§ RAG ç³»ç»Ÿå¿«é€Ÿæ­å»º

2. **LightRAG** (HKUDS, EMNLP 2025)
   - GitHub: https://github.com/HKUDS/LightRAG
   - Star: 10k+
   - ç‰¹ç‚¹:
     - è½»é‡çº§ä¸”å¿«é€Ÿ
     - çŸ¥è¯†å›¾è°±ç®¡ç†èƒ½åŠ›
     - ä¸ RAG-Anything é›†æˆæ”¯æŒå¤šæ¨¡æ€
   - é€‚ç”¨: ç ”ç©¶é¡¹ç›®å’Œè½»é‡çº§éƒ¨ç½²

3. **Personal RAG System**
   - GitHub: https://github.com/yagebin79386/Peronsal-RAG-System
   - ç‰¹ç‚¹:
     - éšç§ä¼˜å…ˆã€ç¦»çº¿è¿è¡Œ
     - å®Œæ•´çš„ä¸ªäººçŸ¥è¯†ç®¡ç†
     - å‘é‡ + AI åµŒå…¥
   - é€‚ç”¨: ä¸ªäººçŸ¥è¯†åº“åœºæ™¯ï¼ˆä¸æœ¬é¡¹ç›®æœ€ç›¸å…³ï¼‰

#### å‘é‡æ•°æ®åº“

4. **Weaviate**
   - GitHub: https://github.com/weaviate/weaviate
   - Star: 12k+
   - æ–‡æ¡£: https://weaviate.io/developers/weaviate
   - ç‰¹ç‚¹:
     - æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + BM25 + è¿‡æ»¤ï¼‰
     - å†…ç½® reranking
     - å¤šç§Ÿæˆ·æ”¯æŒ
   - PowerShell ç¤ºä¾‹:
     ```powershell
     # ä½¿ç”¨ REST API æŸ¥è¯¢
     $Headers = @{
         "Content-Type" = "application/json"
     }
     $Body = @{
         query = @{
             Get = @{
                 Document = @{
                     nearText = @{
                         concepts = @("é¡¹ç›®è®¨è®º")
                     }
                     limit = 10
                 }
             }
         }
     } | ConvertTo-Json -Depth 10

     Invoke-RestMethod -Uri "http://localhost:8080/v1/graphql" `
         -Method Post -Headers $Headers -Body $Body
     ```

5. **Qdrant**
   - GitHub: https://github.com/qdrant/qdrant
   - Star: 22k+
   - æ–‡æ¡£: https://qdrant.tech/documentation/
   - ç‰¹ç‚¹:
     - Rust ç¼–å†™ï¼Œæé«˜æ€§èƒ½
     - çµæ´»çš„è¿‡æ»¤æ¡ä»¶
     - æ”¯æŒç¨€ç–å‘é‡ï¼ˆSPLADEï¼‰
   - Python ç¤ºä¾‹:
     ```python
     from qdrant_client import QdrantClient
     from qdrant_client.models import Distance, VectorParams

     client = QdrantClient(host="localhost", port=6333)

     # åˆ›å»ºé›†åˆ
     client.create_collection(
         collection_name="personal_kb",
         vectors_config=VectorParams(size=384, distance=Distance.COSINE)
     )

     # æ··åˆæ£€ç´¢
     results = client.query_points(
         collection_name="personal_kb",
         query=query_vector,
         query_filter=Filter(...),
         limit=50
     )
     ```

6. **pgvector** (PostgreSQL æ‰©å±•)
   - GitHub: https://github.com/pgvector/pgvector
   - Star: 15k+
   - ç‰¹ç‚¹:
     - PostgreSQL åŸç”Ÿå‘é‡æ”¯æŒ
     - æ— éœ€é¢å¤–æ•°æ®åº“
     - SQL æŸ¥è¯¢å‘é‡
   - é€‚ç”¨: å°è§„æ¨¡é¡¹ç›®æˆ–å·²ä½¿ç”¨ PostgreSQL

#### RLHF å®ç°

7. **OpenRLHF**
   - GitHub: https://github.com/OpenRLHF/OpenRLHF
   - Star: 3k+
   - ç‰¹ç‚¹:
     - å®Œæ•´çš„ RLHF å·¥ä½œæµï¼ˆSFT + RM + PPOï¼‰
     - æ”¯æŒ Ray + vLLM åŠ é€Ÿ
     - DPO/IPO/KTO ç­‰å¤šç§ç®—æ³•
   - é€‚ç”¨: éœ€è¦å®Œæ•´ RLHF è®­ç»ƒæµç¨‹

8. **instructGOOSE**
   - GitHub: https://github.com/xrsrke/instructGOOSE
   - ç‰¹ç‚¹:
     - ç®€åŒ–çš„ RLHF å®ç°
     - åŸºäº InstructGPT è®ºæ–‡
     - æ•™å­¦å‹å¥½çš„ä»£ç 
   - é€‚ç”¨: å­¦ä¹  RLHF åŸç†

#### è®°å¿†ç®¡ç†

9. **Zep** (Context Engineering Platform)
   - ç½‘ç«™: https://www.getzep.com/
   - GitHub: https://github.com/getzep/zep
   - ç‰¹ç‚¹:
     - æ—¶åºçŸ¥è¯†å›¾è°±
     - è‡ªåŠ¨ä¸Šä¸‹æ–‡ç»„è£…
     - é•¿æœŸè®°å¿†ç®¡ç†
   - é€‚ç”¨: éœ€è¦å¤æ‚è®°å¿†ç®¡ç†çš„ Agent

10. **LangChain**
    - GitHub: https://github.com/langchain-ai/langchain
    - Star: 100k+
    - æ–‡æ¡£: https://python.langchain.com/
    - ç‰¹ç‚¹:
      - ä¸°å¯Œçš„è®°å¿†ç±»å‹ï¼ˆBufferã€Summaryã€Entityï¼‰
      - LangGraph å·¥ä½œæµç¼–æ’
      - å¤§é‡é›†æˆï¼ˆå‘é‡DBã€LLMã€å·¥å…·ï¼‰
    - PowerShell é›†æˆç¤ºä¾‹:
      ```powershell
      # é€šè¿‡ REST API è°ƒç”¨ LangChain æœåŠ¡
      function Invoke-LangChainRAG {
          param(
              [string]$Query,
              [string]$UserId
          )

          $Body = @{
              query = $Query
              user_id = $UserId
              config = @{
                  retriever = "hybrid"
                  reranker = "cross-encoder"
                  memory_window = 10
              }
          } | ConvertTo-Json

          Invoke-RestMethod -Uri "http://localhost:8000/rag/query" `
              -Method Post -Body $Body -ContentType "application/json"
      }
      ```

#### çŸ¥è¯†å›¾è°±

11. **Neo4j**
    - GitHub: https://github.com/neo4j/neo4j
    - æ–‡æ¡£: https://neo4j.com/docs/
    - ç‰¹ç‚¹:
      - æˆç†Ÿçš„å›¾æ•°æ®åº“
      - Cypher æŸ¥è¯¢è¯­è¨€
      - å¼ºå¤§çš„å¯è§†åŒ–å·¥å…·ï¼ˆNeo4j Browserï¼‰
    - PowerShell ç¤ºä¾‹:
      ```powershell
      function Invoke-Neo4jQuery {
          param([string]$CypherQuery)

          $Auth = [Convert]::ToBase64String(
              [Text.Encoding]::ASCII.GetBytes("neo4j:password")
          )

          $Body = @{
              statements = @(
                  @{
                      statement = $CypherQuery
                  }
              )
          } | ConvertTo-Json -Depth 10

          Invoke-RestMethod -Uri "http://localhost:7474/db/data/transaction/commit" `
              -Method Post -Body $Body `
              -Headers @{
                  "Authorization" = "Basic $Auth"
                  "Content-Type" = "application/json"
              }
      }

      # æŸ¥è¯¢ç¤ºä¾‹
      Invoke-Neo4jQuery -CypherQuery @"
      MATCH (u:User {name: 'å£®çˆ¸'})-[:DISCUSSED]->(t:Topic)
      WHERE t.timestamp > datetime() - duration('P30D')
      RETURN t.name, t.description
      "@
      ```

12. **Microsoft GraphRAG**
    - GitHub: https://github.com/microsoft/graphrag
    - Star: 20k+
    - æ–‡æ¡£: https://microsoft.github.io/graphrag/
    - ç‰¹ç‚¹:
      - è‡ªåŠ¨æ„å»ºçŸ¥è¯†å›¾è°±
      - ç¤¾åŒºæ£€æµ‹å’Œå±‚æ¬¡åŒ–æ‘˜è¦
      - å…¨å±€å’Œæœ¬åœ°æ£€ç´¢æ¨¡å¼
    - é€‚ç”¨: éœ€è¦è‡ªåŠ¨åŒ–å›¾è°±æ„å»º

### 4.3 è¯„ä¼°å·¥å…·ä¸åŸºå‡†

13. **RAGAS** (RAG Assessment)
    - GitHub: https://github.com/explodinggradients/ragas
    - æ–‡æ¡£: https://docs.ragas.io/
    - ç‰¹ç‚¹:
      - è‡ªåŠ¨åŒ– RAG è¯„ä¼°æŒ‡æ ‡ï¼ˆFaithfulnessã€Relevanceã€Recallï¼‰
      - æ— éœ€äººå·¥æ ‡æ³¨
      - æ”¯æŒå¤šç§ LLM åç«¯
    - ç¤ºä¾‹:
      ```python
      from ragas import evaluate
      from ragas.metrics import faithfulness, answer_relevance

      result = evaluate(
          dataset,
          metrics=[faithfulness, answer_relevance]
      )
      print(result)
      ```

14. **VectorDBBench**
    - GitHub: https://github.com/zilliztech/VectorDBBench
    - ç‰¹ç‚¹:
      - å¤šå‘é‡æ•°æ®åº“æ€§èƒ½å¯¹æ¯”
      - QPSã€å»¶è¿Ÿã€å¬å›ç‡æµ‹è¯•
      - æ”¯æŒ Milvusã€Weaviateã€Qdrant ç­‰
    - é€‚ç”¨: é€‰æ‹©å‘é‡æ•°æ®åº“æ—¶çš„åŸºå‡†æµ‹è¯•

### 4.4 å­¦ä¹ èµ„æº

#### è§†é¢‘æ•™ç¨‹

- **LangChain å®˜æ–¹æ•™ç¨‹**: https://www.youtube.com/@LangChain
- **Weaviate RAG ç³»åˆ—**: https://www.youtube.com/@Weaviate
- **Anthropic æç¤ºå·¥ç¨‹**: https://www.anthropic.com/prompt-engineering

#### åšå®¢ä¸æ–‡ç« 

- **Pinecone Learning Center**: https://www.pinecone.io/learn/
  - RAGã€Rerankingã€å‘é‡æ£€ç´¢æ·±åº¦æ–‡ç« 
- **Zilliz åšå®¢**: https://zilliz.com/learn/
  - å‘é‡æ•°æ®åº“æœ€ä½³å®è·µ
- **LlamaIndex åšå®¢**: https://www.llamaindex.ai/blog
  - å¤šæ¨¡æ€ RAGã€çŸ¥è¯†å›¾è°±é›†æˆ

#### ç¤¾åŒºè®¨è®º

- **Reddit r/LocalLLaMA**: æœ¬åœ° LLM å’Œ RAG è®¨è®º
- **GitHub Discussions**:
  - https://github.com/open-webui/open-webui/discussions/11821 (RAG æœ€ä½³å®è·µ)
  - https://github.com/weaviate/weaviate/discussions (Weaviate é—®ç­”)

---

## é™„å½• A: PowerShell å®Œæ•´å®ç°ç¤ºä¾‹

### A.1 æ•°æ®æ‘„å…¥è„šæœ¬

```powershell
<#
.SYNOPSIS
    å¤šæºæ•°æ®æ‘„å…¥åˆ°å‘é‡æ•°æ®åº“

.DESCRIPTION
    å¤„ç†å¯¹è¯å†å²ã€ä¸ªäººç¬”è®°ç­‰å¤šç§æ•°æ®æºï¼Œç”ŸæˆåµŒå…¥å‘é‡å¹¶å­˜å‚¨åˆ° Qdrant

.PARAMETER SourceType
    æ•°æ®æ¥æºç±»å‹ï¼šconversation, personal_note, web, feedback

.PARAMETER InputFile
    è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆJSON æ ¼å¼ï¼‰

.EXAMPLE
    Invoke-DataIngestion -SourceType conversation -InputFile "chat_history.json"
#>

function Invoke-DataIngestion {
    [CmdletBinding()]
    param(
        [Parameter(Mandatory = $true)]
        [ValidateSet('conversation', 'personal_note', 'web', 'feedback')]
        [string]$SourceType,

        [Parameter(Mandatory = $true)]
        [string]$InputFile
    )

    # 1. è¯»å–è¾“å…¥æ•°æ®
    $RawData = Get-Content -Path $InputFile | ConvertFrom-Json

    # 2. é…ç½®
    $QdrantUrl = "http://localhost:6333"
    $CollectionName = "personal_kb"
    $OllamaUrl = "http://localhost:11434"

    # 3. å¤„ç†æ¯æ¡æ•°æ®
    foreach ($Item in $RawData) {
        Write-Verbose "å¤„ç†: $($Item.content)"

        # 3.1 æ•°æ®æ¸…æ´—
        $CleanedText = $Item.content -replace '\s+', ' '

        # 3.2 ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆè°ƒç”¨ Ollamaï¼‰
        $EmbeddingResponse = Invoke-RestMethod -Uri "$OllamaUrl/api/embeddings" `
            -Method Post `
            -Body (@{
                model = "nomic-embed-text"
                prompt = $CleanedText
            } | ConvertTo-Json) `
            -ContentType "application/json"

        $DenseVector = $EmbeddingResponse.embedding

        # 3.3 è´¨é‡è¯„åˆ†
        $QualityScore = Get-ContentQualityScore -Content $CleanedText

        # åªå­˜å‚¨é«˜è´¨é‡æ•°æ®
        if ($QualityScore -lt 0.7) {
            Write-Warning "è´¨é‡åˆ†æ•°è¿‡ä½ ($QualityScore)ï¼Œè·³è¿‡: $($CleanedText.Substring(0, 50))..."
            continue
        }

        # 3.4 æ„å»ºå‘é‡æ•°æ®åº“æ–‡æ¡£
        $DocumentId = [guid]::NewGuid().ToString()
        $Point = @{
            id = $DocumentId
            vector = $DenseVector
            payload = @{
                content = $CleanedText
                source_type = $SourceType
                timestamp = (Get-Date).ToUniversalTime().ToString("o")
                quality_score = $QualityScore
                user_id = $env:USERNAME
                metadata = $Item.metadata
            }
        }

        # 3.5 ä¸Šä¼ åˆ° Qdrant
        $UploadBody = @{
            points = @($Point)
        } | ConvertTo-Json -Depth 10

        $Response = Invoke-RestMethod -Uri "$QdrantUrl/collections/$CollectionName/points" `
            -Method Put `
            -Body $UploadBody `
            -ContentType "application/json"

        if ($Response.status -eq "ok") {
            Write-Host "âœ“ æˆåŠŸå­˜å‚¨: $DocumentId" -ForegroundColor Green
        } else {
            Write-Error "âœ— å­˜å‚¨å¤±è´¥: $($Response.result)"
        }
    }
}

function Get-ContentQualityScore {
    [CmdletBinding()]
    param([string]$Content)

    # ç®€åŒ–çš„è´¨é‡è¯„åˆ†ï¼ˆå®é™…åº”ä½¿ç”¨ LLMï¼‰
    $Score = 1.0

    # é•¿åº¦æ£€æŸ¥
    if ($Content.Length -lt 10) {
        $Score *= 0.3
    }

    # è¯­è¨€è´¨é‡ï¼ˆç®€å•æ£€æŸ¥ï¼‰
    $WordCount = ($Content -split '\s+').Count
    if ($WordCount -lt 5) {
        $Score *= 0.5
    }

    # æ£€æµ‹åƒåœ¾å†…å®¹
    $SpamPatterns = @('ç‚¹å‡»è¿™é‡Œ', 'ç«‹å³è´­ä¹°', 'http://bit.ly')
    foreach ($Pattern in $SpamPatterns) {
        if ($Content -match $Pattern) {
            $Score *= 0.1
        }
    }

    return $Score
}
```

### A.2 æ··åˆæ£€ç´¢è„šæœ¬

```powershell
<#
.SYNOPSIS
    HybridRAG æ··åˆæ£€ç´¢

.DESCRIPTION
    ç»“åˆå‘é‡æ£€ç´¢ã€BM25 å’ŒçŸ¥è¯†å›¾è°±è¿›è¡Œæ··åˆæ£€ç´¢å¹¶é‡æ’åº
#>

function Invoke-HybridSearch {
    [CmdletBinding()]
    param(
        [Parameter(Mandatory = $true)]
        [string]$Query,

        [Parameter(Mandatory = $false)]
        [int]$TopK = 10,

        [Parameter(Mandatory = $false)]
        [string]$UserId = $env:USERNAME
    )

    Write-Host "ğŸ” æ‰§è¡Œæ··åˆæ£€ç´¢: $Query" -ForegroundColor Cyan

    # é…ç½®
    $QdrantUrl = "http://localhost:6333"
    $CollectionName = "personal_kb"
    $OllamaUrl = "http://localhost:11434"

    # 1. æŸ¥è¯¢å‘é‡åŒ–
    Write-Verbose "ç”ŸæˆæŸ¥è¯¢åµŒå…¥..."
    $EmbeddingResponse = Invoke-RestMethod -Uri "$OllamaUrl/api/embeddings" `
        -Method Post `
        -Body (@{
            model = "nomic-embed-text"
            prompt = $Query
        } | ConvertTo-Json) `
        -ContentType "application/json"

    $QueryVector = $EmbeddingResponse.embedding

    # 2. å‘é‡æ£€ç´¢
    Write-Verbose "æ‰§è¡Œå‘é‡æ£€ç´¢..."
    $VectorSearchBody = @{
        vector = $QueryVector
        filter = @{
            must = @(
                @{
                    key = "user_id"
                    match = @{ value = $UserId }
                }
            )
        }
        limit = 50
        with_payload = $true
    } | ConvertTo-Json -Depth 10

    $VectorResults = Invoke-RestMethod `
        -Uri "$QdrantUrl/collections/$CollectionName/points/search" `
        -Method Post `
        -Body $VectorSearchBody `
        -ContentType "application/json"

    # 3. BM25 æ£€ç´¢ï¼ˆæ¨¡æ‹Ÿï¼Œå®é™…åº”ä½¿ç”¨ Qdrant çš„ç¨€ç–å‘é‡ï¼‰
    Write-Verbose "æ‰§è¡Œ BM25 æ£€ç´¢..."
    $BM25Results = Invoke-BM25Search -Query $Query -UserId $UserId -TopK 30

    # 4. Reciprocal Rank Fusion
    Write-Verbose "èåˆæ£€ç´¢ç»“æœ..."
    $FusedResults = Merge-SearchResults -VectorResults $VectorResults.result `
                                        -BM25Results $BM25Results

    # 5. Rerankingï¼ˆè°ƒç”¨ Ollama è¿›è¡Œé‡æ’åºï¼‰
    Write-Verbose "é‡æ’åº..."
    $RerankedResults = Invoke-Reranking -Query $Query -Candidates $FusedResults -TopK $TopK

    # 6. è¿”å›ç»“æœ
    Write-Host "âœ“ æ£€ç´¢å®Œæˆï¼Œè¿”å› Top-$TopK ç»“æœ" -ForegroundColor Green
    return $RerankedResults
}

function Invoke-BM25Search {
    [CmdletBinding()]
    param(
        [string]$Query,
        [string]$UserId,
        [int]$TopK
    )

    # ç®€åŒ–å®ç°ï¼šä½¿ç”¨ PowerShell çš„ Select-String æ¨¡æ‹Ÿ BM25
    # å®é™…åº”ä½¿ç”¨ Qdrant çš„ç¨€ç–å‘é‡æˆ– Elasticsearch

    $AllDocs = Get-AllDocuments -UserId $UserId
    $QueryTerms = $Query -split '\s+' | Where-Object { $_.Length -gt 2 }

    $Scored = $AllDocs | ForEach-Object {
        $Doc = $_
        $Score = 0

        foreach ($Term in $QueryTerms) {
            $TermFreq = ([regex]::Matches($Doc.content, $Term, 'IgnoreCase')).Count
            if ($TermFreq -gt 0) {
                $Score += [Math]::Log(1 + $TermFreq)
            }
        }

        [PSCustomObject]@{
            doc_id = $Doc.id
            content = $Doc.content
            bm25_score = $Score
            retrieval_method = 'bm25'
        }
    }

    return $Scored | Sort-Object -Property bm25_score -Descending | Select-Object -First $TopK
}

function Merge-SearchResults {
    [CmdletBinding()]
    param(
        [array]$VectorResults,
        [array]$BM25Results
    )

    $DocScores = @{}
    $k = 60  # RRF å¸¸æ•°

    # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
    for ($i = 0; $i -lt $VectorResults.Count; $i++) {
        $DocId = $VectorResults[$i].id
        $RRFScore = 1.0 / ($k + $i + 1)

        if (-not $DocScores.ContainsKey($DocId)) {
            $DocScores[$DocId] = @{
                score = 0
                methods = @()
                content = $VectorResults[$i].payload.content
            }
        }

        $DocScores[$DocId].score += $RRFScore
        $DocScores[$DocId].methods += 'vector'
    }

    # å¤„ç† BM25 ç»“æœ
    for ($i = 0; $i -lt $BM25Results.Count; $i++) {
        $DocId = $BM25Results[$i].doc_id
        $RRFScore = 1.0 / ($k + $i + 1)

        if (-not $DocScores.ContainsKey($DocId)) {
            $DocScores[$DocId] = @{
                score = 0
                methods = @()
                content = $BM25Results[$i].content
            }
        }

        $DocScores[$DocId].score += $RRFScore
        $DocScores[$DocId].methods += 'bm25'
    }

    # æ’åºå¹¶è¿”å›
    $Fused = $DocScores.GetEnumerator() | Sort-Object -Property { $_.Value.score } -Descending

    return $Fused | ForEach-Object {
        [PSCustomObject]@{
            doc_id = $_.Key
            rrf_score = $_.Value.score
            methods = $_.Value.methods -join ','
            content = $_.Value.content
        }
    }
}

function Invoke-Reranking {
    [CmdletBinding()]
    param(
        [string]$Query,
        [array]$Candidates,
        [int]$TopK
    )

    # ä½¿ç”¨ Ollama LLM è¿›è¡Œé‡æ’åº
    $OllamaUrl = "http://localhost:11434"
    $Reranked = @()

    foreach ($Candidate in $Candidates | Select-Object -First 50) {
        # æ„å»ºé‡æ’åºæç¤º
        $Prompt = @"
Query: $Query
Document: $($Candidate.content)

Rate the relevance of this document to the query on a scale of 0-10.
Respond with ONLY a number.
"@

        $Response = Invoke-RestMethod -Uri "$OllamaUrl/api/generate" `
            -Method Post `
            -Body (@{
                model = "llama3.2"
                prompt = $Prompt
                stream = $false
            } | ConvertTo-Json) `
            -ContentType "application/json"

        # æå–åˆ†æ•°
        $RelevanceScore = [double]($Response.response -replace '[^\d.]', '')

        $Reranked += [PSCustomObject]@{
            doc_id = $Candidate.doc_id
            content = $Candidate.content
            rrf_score = $Candidate.rrf_score
            rerank_score = $RelevanceScore
            final_score = $Candidate.rrf_score * 0.4 + $RelevanceScore * 0.6
        }
    }

    return $Reranked | Sort-Object -Property final_score -Descending | Select-Object -First $TopK
}

function Get-AllDocuments {
    [CmdletBinding()]
    param([string]$UserId)

    # ä» Qdrant è·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆå®é™…åº”åˆ†é¡µï¼‰
    $QdrantUrl = "http://localhost:6333"
    $CollectionName = "personal_kb"

    $Response = Invoke-RestMethod -Uri "$QdrantUrl/collections/$CollectionName/points/scroll" `
        -Method Post `
        -Body (@{
            filter = @{
                must = @(
                    @{
                        key = "user_id"
                        match = @{ value = $UserId }
                    }
                )
            }
            limit = 1000
            with_payload = $true
        } | ConvertTo-Json -Depth 10) `
        -ContentType "application/json"

    return $Response.result.points | ForEach-Object {
        [PSCustomObject]@{
            id = $_.id
            content = $_.payload.content
        }
    }
}
```

---

## é™„å½• B: å¿«é€Ÿå¯åŠ¨æŒ‡å—

### B.1 ç¯å¢ƒæ­å»ºï¼ˆWindowsï¼‰

```powershell
# 1. å®‰è£… Qdrantï¼ˆä½¿ç”¨ Dockerï¼‰
docker run -d -p 6333:6333 -p 6334:6334 `
    -v ${PWD}/qdrant_storage:/qdrant/storage `
    qdrant/qdrant

# 2. åˆ›å»ºé›†åˆ
$Body = @{
    vectors = @{
        size = 768
        distance = "Cosine"
    }
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:6333/collections/personal_kb" `
    -Method Put -Body $Body -ContentType "application/json"

# 3. å®‰è£… Neo4jï¼ˆå¯é€‰ï¼Œç”¨äºçŸ¥è¯†å›¾è°±ï¼‰
docker run -d -p 7474:7474 -p 7687:7687 `
    -e NEO4J_AUTH=neo4j/password `
    neo4j:latest

# 4. éªŒè¯ Ollama è¿è¡Œ
ollama list
ollama pull nomic-embed-text  # åµŒå…¥æ¨¡å‹
ollama pull llama3.2          # ç”Ÿæˆæ¨¡å‹

Write-Host "âœ“ ç¯å¢ƒæ­å»ºå®Œæˆï¼" -ForegroundColor Green
```

### B.2 æµ‹è¯•ç¤ºä¾‹

```powershell
# æµ‹è¯•æ•°æ®æ‘„å…¥
$TestData = @(
    @{
        content = "2025å¹´1æœˆ14æ—¥ï¼Œæˆ‘å’Œå¼ ä¸‰è®¨è®ºäº†é¡¹ç›®Xçš„æŠ€æœ¯æ–¹æ¡ˆï¼Œå†³å®šä½¿ç”¨HybridRAGæ¶æ„"
        metadata = @{
            participants = @("å¼ ä¸‰")
            topics = @("é¡¹ç›®X", "HybridRAG")
        }
    },
    @{
        content = "é¡¹ç›®Xéœ€è¦åœ¨2æœˆ1æ—¥å‰å®ŒæˆåŸå‹å¼€å‘ï¼Œé‡ç‚¹æ˜¯å‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±é›†æˆ"
        metadata = @{
            deadline = "2025-02-01"
            topics = @("é¡¹ç›®X")
        }
    }
) | ConvertTo-Json

$TestData | Out-File -FilePath "test_data.json" -Encoding UTF8

# æ‰§è¡Œæ‘„å…¥
Invoke-DataIngestion -SourceType conversation -InputFile "test_data.json" -Verbose

# æµ‹è¯•æ£€ç´¢
$Results = Invoke-HybridSearch -Query "é¡¹ç›®Xçš„æŠ€æœ¯æ–¹æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ" -TopK 5

# æ˜¾ç¤ºç»“æœ
$Results | Format-Table -Property doc_id, final_score, @{
    Label = "Content"
    Expression = { $_.content.Substring(0, [Math]::Min(100, $_.content.Length)) + "..." }
}
```

---

## ç»“è®º

æœ¬æŠ¥å‘Šæ·±å…¥ç ”ç©¶äº†**å‘é‡æ•°æ®åº“åé¦ˆæœºåˆ¶**å’Œ**ä¸ªæ€§åŒ–çŸ¥è¯†åº“æ„å»º**çš„æœ€ä½³å®è·µï¼Œæ ¸å¿ƒå»ºè®®æ€»ç»“å¦‚ä¸‹ï¼š

### å…³é”®è¦ç‚¹

1. **åé¦ˆæœºåˆ¶**
   - é‡‡ç”¨**æ··åˆåé¦ˆ**ï¼ˆæ˜¾å¼ ğŸ‘/ğŸ‘ + éšå¼è¡Œä¸ºï¼‰
   - å®æ–½**ä¸‰å±‚è´¨é‡æ§åˆ¶**ï¼ˆç”Ÿæˆå‰/å/å…¥åº“å‰ï¼‰
   - ä½¿ç”¨**æ—¶é—´è¡°å‡æƒé‡**å’Œ**ç”¨æˆ·ä¿¡èª‰ç³»ç»Ÿ**é˜²æ­¢æ±¡æŸ“

2. **ä¸ªæ€§åŒ–çŸ¥è¯†åº“**
   - ä½¿ç”¨ **HybridRAG** æ¶æ„ï¼ˆå‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±ï¼‰
   - æ„å»º**ç”¨æˆ·åå¥½æ¨¡å‹**å®ç°ä¸ªæ€§åŒ–é‡æ’åº
   - å®æ–½**åˆ†å±‚è®°å¿†ç®¡ç†**ï¼ˆçŸ­æœŸ/å·¥ä½œ/é•¿æœŸï¼‰

3. **æŠ€æœ¯æ ˆæ¨è**
   - å‘é‡æ•°æ®åº“: **Qdrant** æˆ– **Weaviate**
   - çŸ¥è¯†å›¾è°±: **Neo4j**
   - RAG æ¡†æ¶: **LangChain** + **LangGraph**
   - Reranker: **cross-encoder/ms-marco-MiniLM-L-6-v2**

### å®æ–½å»ºè®®

å¯¹äº**è¯­éŸ³é€šçŸ¥é¡¹ç›®**çš„å…·ä½“åº”ç”¨ï¼š

1. **Phase 1** (2-3å‘¨): æ­å»ºåŸºç¡€å‘é‡æ£€ç´¢ + ç®€å•åé¦ˆæ”¶é›†
2. **Phase 2** (3-4å‘¨): å¢å¼ºè´¨é‡æ§åˆ¶ + æ··åˆæ£€ç´¢
3. **Phase 3** (4-5å‘¨): çŸ¥è¯†å›¾è°± + ä¸ªæ€§åŒ–å¼•æ“
4. **Phase 4** (æŒç»­): RLHF è®­ç»ƒ + æŒç»­ä¼˜åŒ–

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

å£®çˆ¸ï¼Œå»ºè®®ä½ ï¼š

1. **é€‰æ‹©èµ·ç‚¹**: æ ¹æ®é¡¹ç›®è§„æ¨¡å†³å®šä» Phase 1 è¿˜æ˜¯ç›´æ¥è·³åˆ° Phase 2
2. **æŠ€æœ¯éªŒè¯**: ä½¿ç”¨é™„å½• B çš„ä»£ç å¿«é€ŸéªŒè¯ Qdrant + Ollama çš„å¯è¡Œæ€§
3. **æ•°æ®å‡†å¤‡**: æ•´ç†ç°æœ‰çš„å¯¹è¯å†å²æ•°æ®ï¼ŒæŒ‰ç…§ç»Ÿä¸€ Schema æ ¼å¼åŒ–
4. **åŸå‹å¼€å‘**: å…ˆå®ç°æ ¸å¿ƒçš„æ··åˆæ£€ç´¢åŠŸèƒ½ï¼Œå†é€æ­¥æ·»åŠ åé¦ˆå’Œä¸ªæ€§åŒ–

---

**æŠ¥å‘Šå®Œæˆæ—¶é—´**: 2025-01-14
**åç»­æ›´æ–°**: å»ºè®®æ¯å­£åº¦å›é¡¾æœ€æ–°ç ”ç©¶è¿›å±•å¹¶æ›´æ–°æœ¬æŠ¥å‘Š

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„æŠ€æœ¯ç»†èŠ‚ï¼Œè¯·éšæ—¶è”ç³»ï¼
